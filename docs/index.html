<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="MSc Global Change Geography" />


<title>Earth Observation</title>
<!-- Material Design fonts -->
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/icon?family=Material+Icons">
<script src="index_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="index_files/bootstrap-3.3.6/css/bootstrap.min.css" rel="stylesheet" />
<script src="index_files/bootstrap-3.3.6/js/bootstrap.min.js"></script>
<script src="index_files/jqueryui-1.11.4/jquery-ui.min.js"></script>
<script src="index_files/navigation-1.1/tabsets.js"></script>
<script src="index_files/navigation-1.1/codefolding.js"></script>
<link href="index_files/magnific-popup-1.1.0/magnific-popup.css" rel="stylesheet" />
<script src="index_files/magnific-popup-1.1.0/jquery.magnific-popup.min.js"></script>
<link href="index_files/bootstrap_material-0.1/bootstrap-material-design.min.css" rel="stylesheet" />
<link href="index_files/bootstrap_material-0.1/ripples.min.css" rel="stylesheet" />
<script src="index_files/bootstrap_material-0.1/material.min.js"></script>
<script src="index_files/bootstrap_material-0.1/ripples.min.js"></script>
<link href="index_files/material-0.1/material.css" rel="stylesheet" />
<script src="index_files/material-0.1/material.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span. { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>

<link rel="stylesheet" href="material_adjust.css" type="text/css" />

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->

</head>

<body>

<div class="header-panel shadow z-2">
    <div class="container-fluid">
        <div class="row">
            <div class="col-xs-3">
        <div id="header">
    <h1 class="title">Earth Observation</h1>
                <h4 class="author">MSc Global Change Geography</h4>
                <h4 class="date">Summer term 2019</h4>
        </div>
    </div>
</div>
</div>
</div>


<div class="container-fluid main-container">
    <div class="row">
      <nav class="col-xs-3 menu">
        <div id="toc">
        <ul>
        <li><a href="#hello">Hello!</a></li>
        <li><a href="#introducing-r">Introducing R</a></li>
        <li><a href="#course-materials">Course materials</a></li>
        <li><a href="#session-01-handling-rasters-in-r">Session 01: Handling rasters in R</a></li>
        <li><a href="#session-02-from-dns-to-toa">Session 02: From DNs to TOA</a></li>
        <li><a href="#session-02-data-quality-cloud-masking">Session 02: Data quality &amp; cloud masking</a></li>
        <li><a href="#session-03-vegetation-indices-and-data-transforms">Session 03: Vegetation indices and data transforms</a></li>
        <li><a href="#session-03-training-data-collection">Session 03: Training data collection</a></li>
        <li><a href="#session-04-pixel-based-compositing">Session 04: Pixel-based compositing</a></li>
        <li><a href="#session-05-machine-learning-for-image-classification">Session 05: Machine learning for image classification</a></li>
        <li><a href="#session-06-accuracy-assessment-and-area-estimation">Session 06: Accuracy assessment and area estimation</a></li>
        <li><a href="#session-07-multi-temporal-change-detection">Session 07: Multi-temporal change detection</a></li>
        <li><a href="#session-08-spectral-temporal-metrics">Session 08: Spectral-temporal metrics</a></li>
        <li><a href="#project-work">Project work</a></li>
        <li><a href="#terminology">Terminology</a></li>
        </ul>
        </div>
        
        
        
      </nav>
     <div class="pages col-xs-9">
     <div class="row">
       <div class="col-xs-10">



<div id="hello" class="section level1">
<h1>Hello!</h1>
<p><img src="fig/header.png" /></p>
<div id="about-earth-observation" class="section level2">
<h2>About Earth Observation</h2>
<p>Earth Observation is an advanced course for students of the Master of Science <a href="https://www.geographie.hu-berlin.de/en/studies/study-programs/master-degree-programs/master-of-science">“Global Change Geography”</a> of Humboldt-Universität zu Berlin. In this course, we cover multiple aspects of optical remote sensing by working with multi-sprectral Landsat and Sentinel 2 imagery. The course is fully based on open source software, including R and QGIS.</p>
<hr />
</div>
<div id="learning-goals-course-contents" class="section level2">
<h2>Learning goals &amp; course contents</h2>
<p>The main goal of this course is to provide you with the necessary knowledge and tools for using optical remote sensing datasets and methods in the geo-scientific context. We want you to enhance your ability of problem-solving, empowering you to perform research independently. To that end, we cover aspects of data acquisition, spatial data handling in R and QGIS, basics of image pre-processing, higher-level processing such as pixel-based compositing and time-series binning. The course contents are related to our lab´s research foci, both in terms of methods and study regions. You may want to check out our <a href="https://www.geographie.hu-berlin.de/en/professorships/geomatics/publications-en">publications</a>, <a href="https://www.geographie.hu-berlin.de/en/professorships/geomatics/projects">current projects</a>, or have a look at <a href="https://www2.hu-berlin.de/geomultisens/europeanLandCover/euroLandCover.html">this example</a>.</p>
<p>In the course you will learn about current state-of-the-art methods in image processing and time series analyses of optical satellite imagery. The course covers methods related to data quality, cloud masking, vegetation indices, multi-temporal image analyses, machine learning classification algorithms, area adjusted accuracy assessment, time series analyses, and image compositing. We use these methods for mapping of forest types, forest cover changes, agricultural dynamics in the Carpathian ecoregion (Poland), the Southern Brazilian Amazon, and Crete in Greece.</p>
<hr />
</div>
<div id="requirements" class="section level2">
<h2>Requirements</h2>
<p>A good understanding of basic principles of remote sensing is needed to follow this course. Participants should furthermore have a basic understanding of R, including syntax, data types and knowledge on how to read, manipulate and write data. As you followed the curriculum of the MSc program, you most likely joined the module “Quantitative Methods for Geographers”, in which you learned using R for statistical problems. Here, we built on your existing knowledge. If you are not enrolled in the MSc program, feel free to look at the <a href="https://github.com/corneliussenf/quantitative_methods">course materials</a>.</p>
<p>Alternatively, you may want to follow one of the numerous tutorials for R fundamentals (e.g., <a href="https://www.rstudio.com/online-learning/">RStudio</a>, <a href="https://www.datacamp.com/courses/free-introduction-to-r">DataCamp</a>, <a href="http://www.r-tutorial.nl/">UMC Utrecht</a>, <a href="http://adv-r.had.co.nz/">Advanced R by Hadley Wickham</a>, <a href="https://r-graphics.org/">R Graphics Cookbook</a>), or one of those specifically for geodata processing (e.g., <a href="https://geoscripting-wur.github.io/">Wageningen University</a>, <a href="https://www.earthdatascience.org/">University of Colorado</a>).</p>
<hr />
<!-- ################################## INTRO R ############################################## -->
</div>
</div>
<div id="introducing-r" class="section level1">
<h1>Introducing R</h1>
<div id="why-do-we-use-r" class="section level2">
<h2>Why do we use R?</h2>
<p>R is a programming language and open source software environment for statistical computing and graphics. The R language is widely used among statisticians and data miners for developing statistical software and data analysis. It was developed by Ross Ihaka and Robert Gentleman at the University of Auckland, New Zealand. The name R originates the first names of the two authors and refers to the programming language S. The project was conceived in 1992, with an initial version released in 1995 and a stable beta version in 2000.</p>
<p>Learning R has tons of advantages. It is a great starting point for those eager to learn programming. R offers increasingly specialized tools for data wrangling, statistical analyses, and visualization. The CRAN package repository currently features &gt;13,000 packages serving a variety of purposes, e.g. data manipulation (<code>tidyr</code>, <code>dplyr</code>, <code>caret</code>), visualization (<code>ggplot2</code>, <code>ggmap</code>, <code>rasterVis</code>), and geodata handling (<code>raster</code>, <code>rgdal</code>, <code>sp</code>, <code>sf</code>). You will notice that a huge share of figures in scientific publications was produced using R. The R community is huge, and offers great support. R is extremely popular in science &amp; industry, so a proficiency in R opens a wide array of job opportunities. Everything is free and open source.</p>
<div class="figure">
<img src="fig/fig00.png" alt="A rising tide for R (Tipman 2015; doi: 10.1038/517109a)" />
<p class="caption">A rising tide for R (Tipman 2015; doi: 10.1038/517109a)</p>
</div>
<hr />
</div>
<div id="coding-style" class="section level2">
<h2>Coding style</h2>
<p>A few basic rules apply to coding in R. Here is a short summary of <a href="http://adv-r.had.co.nz/Style.html">Hadley Wickham´s style guide</a>:</p>
<ul>
<li>Regularly save your progress.</li>
<li><p>Script names should be meaningful and end in ‘.R’.</p></li>
<li>Comment (#) your code &amp; separate it into readable chunks.</li>
<li><p>Try to limit your code to 80 characters per line.</p></li>
<li>Variable and function names should be lowercase.</li>
<li><p>Variable names should be nouns and function names verbs.</p></li>
<li>Place spaces around operators (=, +, -, &lt;-, etc.) and after commas.</li>
<li><p>Use &lt;-, not =, for assignment.</p></li>
</ul>
<p>An example:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" title="1"><span class="co">######################################################</span></a>
<a class="sourceLine" id="cb1-2" title="2"><span class="co"># Creating random data and a correlated response </span></a>
<a class="sourceLine" id="cb1-3" title="3"><span class="co"># Philippe Rufin, 2019</span></a>
<a class="sourceLine" id="cb1-4" title="4"></a>
<a class="sourceLine" id="cb1-5" title="5"><span class="co"># Load all required packages</span></a>
<a class="sourceLine" id="cb1-6" title="6"><span class="kw">library</span>(ggplot2)</a>
<a class="sourceLine" id="cb1-7" title="7"></a>
<a class="sourceLine" id="cb1-8" title="8"><span class="co"># Create random data</span></a>
<a class="sourceLine" id="cb1-9" title="9">x &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">50</span>, <span class="dv">0</span>, <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb1-10" title="10"></a>
<a class="sourceLine" id="cb1-11" title="11"><span class="co"># Build function to simulate response</span></a>
<a class="sourceLine" id="cb1-12" title="12">create.response &lt;-<span class="st"> </span><span class="cf">function</span>(x){x <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">50</span>, <span class="dv">0</span>, <span class="fl">0.2</span>)}</a>
<a class="sourceLine" id="cb1-13" title="13"></a>
<a class="sourceLine" id="cb1-14" title="14"><span class="co"># Apply function to random data</span></a>
<a class="sourceLine" id="cb1-15" title="15">y &lt;-<span class="st"> </span><span class="kw">create.response</span>(x)</a>
<a class="sourceLine" id="cb1-16" title="16"></a>
<a class="sourceLine" id="cb1-17" title="17"><span class="co"># Make a dataframe</span></a>
<a class="sourceLine" id="cb1-18" title="18">data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="st">&#39;x&#39;</span> =<span class="st"> </span>x, <span class="st">&#39;y&#39;</span> =<span class="st"> </span>y)</a>
<a class="sourceLine" id="cb1-19" title="19"></a>
<a class="sourceLine" id="cb1-20" title="20"><span class="co"># Plot the simulated dataset</span></a>
<a class="sourceLine" id="cb1-21" title="21"><span class="kw">ggplot</span>(data, <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span></a>
<a class="sourceLine" id="cb1-22" title="22"><span class="st">  </span><span class="kw">geom_point</span>()</a></code></pre></div>
<p><img src="index_files/figure-html/style-1.png" width="288" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" title="1"><span class="co"># Investigate correlation in the data</span></a>
<a class="sourceLine" id="cb2-2" title="2"><span class="kw">cor</span>(data<span class="op">$</span>x, data<span class="op">$</span>y)</a></code></pre></div>
<pre><code>[1] 0.9408059</code></pre>
<hr />
</div>
<div id="help" class="section level2">
<h2>Help!</h2>
<p>If you get stuck, there are plenty of things you can do:</p>
<ul>
<li>Seek the function´s help page (i.e. highlight the function and hit F1)</li>
<li>Search your problem or error message</li>
<li>Ask your colleagues</li>
<li>Use the moodle course forum</li>
<li>Check forums (e.g., <a href="https://stackoverflow.com/">StackOverflow</a>)</li>
</ul>
<hr />
</div>
</div>
<div id="course-materials" class="section level1">
<h1>Course materials</h1>
<div id="readings" class="section level2">
<h2>Readings</h2>
<p>The first sessions of the course contain reading materials, such as are peer-reviewed papers and technical reports. You will find the reading materials for the next session at the end of each session. We highlight aspects to focus upon to streamline the reading process and facilitate the discussion. We are looking forward to lively discussions of the reading materials and critical questions from your end.</p>
</div>
<div id="data" class="section level2">
<h2>Data</h2>
<p>All data used in the course is openly accessible. Mostly, we´ll be working with Landsat images, which you can access through the USGS Earth Explorer. We provide download links to the datasets for each session. It will be helpful if you organize your data in a course directory on your local machine (MSc students might want to use drive <code>O:/Student_Data/your_name/EO/</code>). We will refer to this folder as <code>course.dir</code> throughout this course. Create subdirectories for each session, e.g. <code>course.dir/S01/</code> and separate data, code and course materials in additional sub-directories (e.g. <code>/data</code>, <code>/code</code>, <code>/docs</code>).</p>
</div>
<div id="exercises" class="section level2">
<h2>Exercises</h2>
<p>The weekly exercises are defined in the respective session. Each session comprises several tasks that involve scipting in R. Course participants must submit completed exercises, documented as R scripts, in <a href="http://moodle.hu-berlin.de/">moodle</a> to pass. Weekly submission deadlines are every sunday, 23:59. Please name the script of your work group as SXX_name1_name2.R, e.g. S01_ernst_rufin.R. Please structure your script for every exercise as follows:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" title="1"><span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb4-2" title="2"><span class="co"># MSc Earth Observation Exercise [Session number]</span></a>
<a class="sourceLine" id="cb4-3" title="3"><span class="co"># [Your Name]</span></a>
<a class="sourceLine" id="cb4-4" title="4"><span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb4-5" title="5"></a>
<a class="sourceLine" id="cb4-6" title="6"><span class="co"># Load packages, use install.packages(&#39;packagename&#39;) to install if needed</span></a>
<a class="sourceLine" id="cb4-7" title="7"><span class="kw">library</span>(raster)</a>
<a class="sourceLine" id="cb4-8" title="8"></a>
<a class="sourceLine" id="cb4-9" title="9"><span class="co"># Change raster options to store large rasters in temp files on disk</span></a>
<a class="sourceLine" id="cb4-10" title="10"><span class="kw">rasterOptions</span>(<span class="dt">maxmemory =</span> <span class="fl">1e6</span>)</a>
<a class="sourceLine" id="cb4-11" title="11"></a>
<a class="sourceLine" id="cb4-12" title="12"><span class="co"># Define the folder that contains your data...</span></a>
<a class="sourceLine" id="cb4-13" title="13">data.dir &lt;-<span class="st"> &#39;course.dir/S01/data/&#39;</span></a>
<a class="sourceLine" id="cb4-14" title="14"></a>
<a class="sourceLine" id="cb4-15" title="15"><span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb4-16" title="16"><span class="co"># 1)    </span></a>
<a class="sourceLine" id="cb4-17" title="17"><span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb4-18" title="18"></a>
<a class="sourceLine" id="cb4-19" title="19"><span class="co"># Comments for task 1</span></a>
<a class="sourceLine" id="cb4-20" title="20"></a>
<a class="sourceLine" id="cb4-21" title="21"></a>
<a class="sourceLine" id="cb4-22" title="22"><span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb4-23" title="23"><span class="co"># 2)    </span></a>
<a class="sourceLine" id="cb4-24" title="24"><span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb4-25" title="25"></a>
<a class="sourceLine" id="cb4-26" title="26"><span class="co"># ...</span></a></code></pre></div>
<!-- ################################## SESSION 01 ############################################## -->
</div>
</div>
<div id="session-01-handling-rasters-in-r" class="section level1">
<h1>Session 01: Handling rasters in R</h1>
<div id="learning-goals" class="section level2">
<h2>Learning goals</h2>
<p>In this session, you will</p>
<ul>
<li>Acquire multi-spectral satellite data</li>
<li>Read &amp; write raster data</li>
<li>Manipulate the spatial extent of rasters</li>
<li>Extract cell values &amp; plot a spectral profile</li>
</ul>
<hr />
</div>
<div id="the-raster-package" class="section level2">
<h2>The <code>raster</code> package</h2>
<p>It´s great, as it facilitates raster data handling. It allows us to access file characteristics before loading data into memory, facilitates handling of coordinate reference systems and spatial extents. We can use it to perform raster algebra, to combine raster and vector datasets (e.g. ESRI shapefiles), or to convert raster files into matrices, which are compatible with the base functions to access image statistics, develop models, slice data dimensions etc.</p>
<p>There are a couple of things that the raster package does not provide. For example, advanced visualization of spatial datasets and manual operations, such collecting training or validation data, are preferably done in a GIS environment (e.g. QGIS). Furthermore, processing large data volumes in R can be quite time-consuming (we often use Python instead, it´s syntax is quite similar to R).</p>
<p>You install the raster package just like any other package in R. Dependencies will automatically be installed. On some machines, you might need to install <code>rgdal</code> manually.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" title="1"><span class="co"># Install the raster and rgdal packages</span></a>
<a class="sourceLine" id="cb5-2" title="2"><span class="kw">install.packages</span>(<span class="st">&#39;raster&#39;</span>)</a>
<a class="sourceLine" id="cb5-3" title="3"><span class="kw">install.packages</span>(<span class="st">&#39;rgdal&#39;</span>)</a>
<a class="sourceLine" id="cb5-4" title="4"></a>
<a class="sourceLine" id="cb5-5" title="5"><span class="co"># Load the package</span></a>
<a class="sourceLine" id="cb5-6" title="6"><span class="kw">library</span>(raster)</a></code></pre></div>
<hr />
</div>
<div id="exercise" class="section level2">
<h2>Exercise</h2>
<div id="data-acquisition" class="section level3">
<h3>1) Data acquisition</h3>
<p>Let´s get some Landsat data. Visit the <a href="http://earthexplorer.usgs.gov/">USGS Earth Explorer</a> and use the Adress/Place field to navigate to Wisła, Poland (lat,lon: 49.6473,18.8677). Switch to the ‘Data Sets’ tab and select Landsat -&gt; Landsat Collection 1 Level-1. Tick the ‘Landsat 8 OLI/TIRS C1 Level 1’ box and click on ‘Results &gt;&gt;’.</p>
<p>You´ll get several hundreds of results, so let´s narrow down the search. Under ‘Search Criteria’, define an acquisition date range between February 2014 and August 2014. Switch to the ‘Additional Criteria’ tab. Let´s choose a scene cloud cover of ‘Less than 40%’, and select the ‘Tier 1’ category.</p>
<p>Find the following images:</p>
<ul>
<li>LC08_L1TP_189025_20140716_20170421_01_T1</li>
<li>LC08_L1TP_189025_20140310_20170425_01_T1</li>
</ul>
<p>Check <a href="https://www.usgs.gov/land-resources/nli/landsat/landsat-collection-1">this website</a> to get an overview of the Landsat Collection 1 file naming convention (product identifiers) and further information such as processing levels.</p>
<p>Visualize the images in the Earth Explorer interface by clicking on the small image icon. For downloading the data, you will need an EarthExplorer account. You may register and download the .tar.gz files. If you prefer not to register, you can <a href="https://box.hu-berlin.de/f/5248da1584054eb6ba51/?dl=1">download the files from our repository</a>. Unpack the files in your session directory.</p>
<hr />
</div>
<div id="reading-data" class="section level3">
<h3>2) Reading data</h3>
<p>Today, you will make use of R´s raster package classes and functions which are well described in the package documentation. Get acquainted with the following classes and functions and find out what they are useful for: <code>raster()</code>, <code>stack()</code> ,<code>extent()</code>, <code>crop()</code>, <code>extract()</code>, <code>CRS()</code>, <code>projectRaster()</code>, <code>plotRGB()</code>, <code>writeRaster()</code></p>
<p>Visit the folder containing the unpacked Landsat image. Did you take a close look at the <a href="https://www.usgs.gov/media/images/landsat-collection-1-product-identifier">Landsat file naming convention</a>? Practically, it provides some basic meta-information. For instance, <code>LC08_L1TP_189025_20140310_20170425_01_T1</code> is a sequence of information on the sensor, processing level, WRS path and row, acquisition date, processing date, collection, and collection tier, separated by ’_’.</p>
<p>As you can see, the Landsat images are delivered as single-band files. The single bands should be stacked for further analyses. For stacking, all input files must have matching extents and the identical projection. Create a stack for each of the two Landsat 8 images.</p>
<p>Important: Please include only the following bands: blue, green, red, near infrared, shortwave infrared 1, shortwave infrared 2 (in this order). Check the list of <a href="https://landsat.usgs.gov/what-are-band-designations-landsat-satellites/">Landsat spectral bands</a> for a recap. Always keep the band designations in mind, as this can cause confusion, e.g. when combining Landsat 5 and Landsat 8 data.</p>
<div class="figure">
<img src="fig/ls_bands.jpg" alt="Band designations for Landsat satellites" style="width:70.0%" />
<p class="caption">Band designations for Landsat satellites</p>
</div>
<p>Try to create the two stacks with a minimum amount of code as possible! Consider using helper functions such as <code>paste0()</code>, <code>dir()</code> or <code>list.files()</code>.</p>
<hr />
</div>
<div id="manipulating-data" class="section level3">
<h3>3) Manipulating data</h3>
<p>Investigate the stack. In which projection is the data delivered?</p>
<p>Compare the extent of the two images. You will notice that they vary. Trying to stack images of different extent will cause an error message claiming:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" title="1">image.stack &lt;-<span class="st"> </span><span class="kw">stack</span>(image.one, image.two)</a>
<a class="sourceLine" id="cb6-2" title="2">Error <span class="cf">in</span> <span class="kw">compareRaster</span>(x) <span class="op">:</span><span class="st"> </span>different extent</a></code></pre></div>
<p>To stack both images, we need to crop (i.e. clip, or cut) the images to their common extent. Find an efficient way to identify the common extent of the images, defined as <code>common.extent &lt;- c(xmin, xmax, ymin, ymax)</code> (in projected coordinates).</p>
<div class="figure">
<img src="fig/fig01.png" alt="Identifying the common extent of several images" />
<p class="caption">Identifying the common extent of several images</p>
</div>
<p>The common extent of the two images is pretty large. In order to reduce the amount of data for the next steps, we should crop the images to our region of interest, a part of the Western Beskids, defined by <code>roi.extent &lt;- c(327945, 380325, 5472105, 5521095)</code></p>
<hr />
</div>
<div id="writing-data" class="section level3">
<h3>4) Writing data</h3>
<p>Write the cropped stacks to your folder using <code>writeRaster()</code>. Use the <code>GTiff</code> format and the <a href="https://www.rdocumentation.org/packages/raster/versions/2.5-8/topics/dataType">appropriate datatype</a>. Why is this important?</p>
<hr />
</div>
<div id="visualizing-data" class="section level3">
<h3>5) Visualizing data</h3>
<p>Open the cropped images in QGIS. Seek the symbology to create a true-color (red, green, blue) and a false-color representation (e.g., RGB: swIR1, nIR, red) of each image. Make sure to properly consider the order of bands in your stack (blue, green, red, nIR, swIR 1, swIR 2) in relation to your computer screen´s color channels (RGB).</p>
<p>Use the <code>plotRGB()</code> function in R to create another false-color visualization of the images in R.</p>
<div class="figure">
<img src="fig/s01_falsecolor_432.png" alt="False color visualization (RGB: nIR, red, green)" />
<p class="caption">False color visualization (RGB: nIR, red, green)</p>
</div>
<hr />
</div>
<div id="extracting-spectral-profiles" class="section level3">
<h3>6) Extracting spectral profiles</h3>
<p>Use the <code>extract()</code> function to get spectral profiles from both images. Use the following coordinate:</p>
<p><code>coordinate &lt;- data.frame('x' = 355623, 'y' = 5486216)</code>.</p>
<p>Visualize the results in R. Can you create one plot that shows two spectral profiles (one for each image in the stack), while accounting for the band wavelength and acquisition date? Can you guess what type of surface we are looking at?</p>
<div class="figure">
<img src="fig/s01_spectra.png" alt="Spectral profiles for two observation dates" style="width:60.0%" />
<p class="caption">Spectral profiles for two observation dates</p>
</div>
<hr />
</div>
</div>
<div id="reading-materials" class="section level2">
<h2>Reading materials</h2>
<p>In the next session, we would like to discuss the following paper:</p>
<p><a href="https://doi.org/10.1016/j.rse.2011.10.028">Zhu, Z., &amp; Woodcock, C.E. (2012). Object-based cloud and cloud shadow detection in Landsat imagery. Remote Sensing of Environment, 118, 83–94.</a></p>
<p>This is a rather technical reading, which introduces the Fmask algorithm for automated cloud and cloud shadow detection. It has been widely used for cloud detection on Landsat TM and ETM+ data, and was enhanced for the use with Landsat OLI and Sentinel 2 data (documented in <a href="https://doi.org/10.1016/j.rse.2014.12.014">Zhu et al. 2015</a>).</p>
<p>While reading focus on the following broad questions:</p>
<ul>
<li>Why do we need automated cloud masking?</li>
<li>How does it work in principle?</li>
<li>Where are the limitations?</li>
</ul>
<p>More specifically, think about the following:</p>
<ul>
<li>How were the thresholds for spectral tests derived?</li>
<li>How will different error types impact further analyses?</li>
</ul>
<!-- ################################## SESSION 02 ############################################## -->
</div>
</div>
<div id="session-02-from-dns-to-toa" class="section level1">
<h1>Session 02: From DNs to TOA</h1>
<hr />
<div id="learning-goals-1" class="section level2">
<h2>Learning goals</h2>
<ul>
<li>Convert digital number values to top-of-atmosphere reflectance</li>
<li>Compare top-of-atmosphere reflectance to surface reflectance</li>
</ul>
<hr />
</div>
<div id="what-is-radiance-what-are-dns" class="section level2">
<h2>What is radiance / what are DNs?</h2>
<p>This session is the most technical of the entire course. Today we will be dealing with physical units, conversion, and data quality. Let´s kick it off with a short recap. Towards the end of the last exercise, you produced a plot of measurements in the different bands of a Landsat image, similar to this one:</p>
<div class="figure">
<img src="fig/s01_spectra.png" alt="Spectral profiles extracted from a Landsat Level 1 image" style="width:60.0%" />
<p class="caption">Spectral profiles extracted from a Landsat Level 1 image</p>
</div>
<p>Our y-axis label was “DN”, or digital number. Now, what is that again? Earth observing sensors, such as the ones on board the Landsat satellites register radiance at the top of the atmosphere. Radiance is expressed in watt per <a href="https://en.wikipedia.org/wiki/Steradian">steradian</a> per square meter.</p>
<p>Storing data in radiance units is difficult and therefore sensors translate measured radiance into DNs. Therefore, the range of energy measured by the sensor is broken into distinct units (DNs). Sensor-specific calibration determines the minimum and maximum amount of radiance that can be measured. DNs express the amount of radiance in relation to these sensor-specific calibration coefficients. The total number of possible DNs is what we refer to as the radiometric resolution of the sensor.</p>
<p>As an example, Landsat 4, 5, and 7 worked with a radiometric resolution of 8 bit. This allows for <code>2^8</code>, or 255 distinct DNs values. Landsat 8 works with 12 bit radiometric resolution, which is artificially quantized to 16 bit. The 16 bit resolution can represent much more different grey shades, exactly <code>2^16</code>, or 65,536 values. Let´s put this into code.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" title="1"><span class="kw">library</span>(raster)</a>
<a class="sourceLine" id="cb7-2" title="2"></a>
<a class="sourceLine" id="cb7-3" title="3"><span class="co"># Define the number of bits</span></a>
<a class="sourceLine" id="cb7-4" title="4">bit &lt;-<span class="st"> </span><span class="dv">4</span></a>
<a class="sourceLine" id="cb7-5" title="5"></a>
<a class="sourceLine" id="cb7-6" title="6"><span class="co"># How many grey tones can we represent given bit?</span></a>
<a class="sourceLine" id="cb7-7" title="7"><span class="kw">print</span>(<span class="kw">paste0</span>(bit, <span class="st">&#39; bits produce &#39;</span>, <span class="dv">2</span><span class="op">^</span>bit, <span class="st">&#39; grey tones.&#39;</span>))</a></code></pre></div>
<pre><code>[1] &quot;4 bits produce 16 grey tones.&quot;</code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" title="1"><span class="co"># Create a raster with one line and 2^bit columns,</span></a>
<a class="sourceLine" id="cb9-2" title="2"><span class="co"># whereas cell values are filled with a vector of numbers from 1 2^bit</span></a>
<a class="sourceLine" id="cb9-3" title="3">r &lt;-<span class="st"> </span><span class="kw">raster</span>(<span class="dt">nrows =</span> <span class="dv">1</span>, <span class="dt">ncols =</span> <span class="dv">2</span><span class="op">^</span>bit, <span class="dt">vals =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span><span class="op">^</span>bit))</a>
<a class="sourceLine" id="cb9-4" title="4"></a>
<a class="sourceLine" id="cb9-5" title="5"><span class="co"># Plot the image and assign grey-scale values to the cells</span></a>
<a class="sourceLine" id="cb9-6" title="6"><span class="kw">image</span>(r, <span class="dt">col =</span> <span class="kw">grey.colors</span>(<span class="dv">2</span><span class="op">^</span>bit, <span class="dt">start =</span> <span class="dv">0</span>, <span class="dt">end =</span> <span class="dv">1</span>), <span class="dt">main =</span> <span class="kw">paste0</span>(bit, <span class="st">&quot; bit raster&quot;</span>))</a></code></pre></div>
<p><img src="index_files/figure-html/greyscale-1.png" width="576" /></p>
<hr />
</div>
<div id="dns-to-toa" class="section level2">
<h2>DNs to TOA</h2>
<p>As DNs are dependent on the sensor calibration, identical measurements yield differing DNs across sensors. DNs are physically not meaningful. Instead of DNs, often we are interested in reflectance. Reflectance expresses the fraction of reflected radiance relative to the total incoming energy (sun), and is scaled between 0 and 1. Many applications require data converted to reflectance and/or corrected for the influence of the atmosphere.</p>
<ul>
<li>Sensor calibration (DN to radiance)</li>
<li>Conversion to top-of-atmosphere reflectance (radiance to TOA)</li>
<li>Atmospheric correction yielding bottom-of-atmosphere reflectance (TOA to BOA, or surface reflectance)</li>
</ul>
<p>A conversion of DNs into radiance can be easily undertaken. By accounting for sun-sensor geometries and solar irradiance, we can easily infer top-of-atmosphere reflectance (TOA) from radiance. This facilitates, e.g., a comparison of measurements from different sensors.</p>
<p>Practically, this involves a linear scaling of the DN values which uses two band-specific rescaling factors. One is multiplicative, one is additive. Formulas are explained in the <a href="https://www.usgs.gov/land-resources/nli/landsat/using-usgs-landsat-level-1-data-product">USGS guide for conversion to TOA Reflectance</a>. With Landsat 8 Collection 1 data, we can use a single set of coefficients to convert DNs to TOA reflectance. Note that this is not the case for all sensors.</p>
<p><span class="math inline">\(ρλ&#39; = M_ρ * Q_{cal} + A_ρ\)</span></p>
<p>where</p>
<p><span class="math inline">\(ρλ&#39;\)</span> = TOA planetary reflectance, without correction for solar angle.</p>
<p><span class="math inline">\(M_ρ\)</span> = Band-specific multiplicative rescaling factor from the metadata.</p>
<p><span class="math inline">\(Q_{cal}\)</span> = Quantized and calibrated standard product pixel values (DN).</p>
<p><span class="math inline">\(A_ρ\)</span> = Band-specific additive rescaling factor from the metadata.</p>
<p>In a next step, we can correct for solar angle during image acquisition.</p>
<p><span class="math inline">\(ρλ = ρλ&#39; / cos(θ_{SZ}) = ρλ&#39; / sin(θ_{SE})\)</span></p>
<p>where</p>
<p><span class="math inline">\(ρλ\)</span> = TOA planetary reflectance corrected for solar angle.</p>
<p><span class="math inline">\(θ_{SZ}\)</span> = Local solar zenith angle, whereas <span class="math inline">\(θ_{SZ} = 90° - θ_{SE}\)</span>.</p>
<p><span class="math inline">\(θ_{SE}\)</span> = Local sun elevation angle.</p>
<hr />
</div>
<div id="toa-to-boa" class="section level2">
<h2>TOA to BOA</h2>
<p>A final step towards comparable measurements of the Earth surface is the atmospheric correction. By doing atmospheric correction, we (theoretically) eliminate the influence of the atmosphere. We therefore call the product “surface reflectance” or “bottom of atmosphere reflectance” (BOA). Theoretically, the space-borne sensor´s measurements should be identical to ground-based measurements.</p>
<hr />
</div>
<div id="exercise-1" class="section level2">
<h2>Exercise</h2>
<p>During this exercise you will learn how to convert Landsat-8 Collection 1 DNs to TOA reflectance, and compare and characterize spectral appearance of different land cover types in TOA and BOA imagery. The data are provided in <a href="https://box.hu-berlin.de/f/97b7bd39ac6d48488f74/?dl=1">our repository</a>. After unpacking, you find the following folders:</p>
<ul>
<li><p>DN/LC08_L1TP_189025_20141105_20170417_01_T1/ - the directory containing the “L1TP” Landsat product (i.e. terrain-corrected (“orthorectified”) data in DNs), including the metadata file (MTL.txt) and the Quality Band (BQA.tif) which contains information on radiometric saturation, clouds, cloud shadows and more.</p></li>
<li><p>SR/LC081890252014110501T1-SC20170927102137/ – the directory containing Level-2 data, i.e. atmospherically corrected, or bottom-of-atmosphere data.</p></li>
</ul>
<div id="dn-to-toa-conversion" class="section level3">
<h3>1) DN to TOA conversion</h3>
<p>Familiarize yourself with the L1TP data. Visualize individual bands, have a look at the Level-1 metadata file (LC08_L1TP_ XXX_MTL.txt) and the information provided within. Again, we only use the six reflective bands of the OLI sensor in this exercise (3xVIS, nIR, 2xswIR)</p>
<p>Read the Landsat metadata file in R using <code>read.delim()</code> and extract the necessary information for the top-of-atmosphere conversion: - <code>REFLECTANCE_MULT_BAND</code> - <code>REFLECTANCE_ADD_BAND</code> - <code>SUN_ELEVATION</code></p>
<p>Use the pattern matching function <code>grep()</code> to find the corresponding entries in the metadata file and store them as numeric vectors. Do this as follows:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" title="1"><span class="co"># Define the folder that contains your data...</span></a>
<a class="sourceLine" id="cb10-2" title="2">path &lt;-<span class="st"> &#39;course.dir/S02/data/DN&#39;</span></a>
<a class="sourceLine" id="cb10-3" title="3"></a>
<a class="sourceLine" id="cb10-4" title="4"><span class="co"># Read MTL file</span></a>
<a class="sourceLine" id="cb10-5" title="5">mtl &lt;-<span class="st"> </span><span class="kw">list.files</span>(data.path, <span class="dt">pattern=</span><span class="st">&quot;MTL.txt$&quot;</span>, <span class="dt">recursive=</span>T, <span class="dt">full.names=</span>T)</a>
<a class="sourceLine" id="cb10-6" title="6">mtl.txt &lt;-<span class="st"> </span><span class="kw">read.delim</span>(mtl, <span class="dt">sep =</span> <span class="st">&#39;=&#39;</span>, <span class="dt">stringsAsFactors =</span> F)</a>
<a class="sourceLine" id="cb10-7" title="7"></a>
<a class="sourceLine" id="cb10-8" title="8"><span class="co"># Extract numeric values</span></a>
<a class="sourceLine" id="cb10-9" title="9">REFLECTANCE_MULT_BAND &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(mtl.txt[<span class="kw">grep</span>(<span class="st">&quot;REFLECTANCE_MULT_BAND&quot;</span>,mtl.txt<span class="op">$</span>GROUP),][<span class="dv">2</span><span class="op">:</span><span class="dv">7</span>,<span class="dv">2</span>])</a></code></pre></div>
<p>Convert the DN values to TOA following the “Conversion to TOA Reflectance” section in the <a href="https://www.usgs.gov/land-resources/nli/landsat/using-usgs-landsat-level-1-data-product">USGS guide for conversion to TOA Reflectance</a>. Important things to keep in mind:</p>
<ul>
<li>You can apply the conversion to all bands in a stack simultaneously.</li>
<li>The Landsat data is provided as integer values. When applying the equation, the data will be cast to float. You will have to re-convert to integer at some point. Use a reflectance scaling factor of 10,000 during the conversion.</li>
<li>The sun elevation angle provided in the metadata file is reported in degrees. The <code>sin()</code> function expects that angles are provided in radians. For the conversion to work correctly, you need to convert <code>SUN_ELEVATION</code> into radians. Make use of this helper function:</li>
</ul>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" title="1"><span class="co"># Helper-function to convert degrees to radians</span></a>
<a class="sourceLine" id="cb11-2" title="2">deg2rad &lt;-<span class="st"> </span><span class="cf">function</span>(deg){ (deg <span class="op">*</span><span class="st"> </span>pi) <span class="op">/</span><span class="st"> </span>(<span class="dv">180</span>) }</a></code></pre></div>
<p>Write the result of your TOA conversion to disk in the <code>GTiff</code> format. Make sure to use an integer data type to save disk space.</p>
</div>
<div id="compare-toa-with-boa" class="section level3">
<h3>2) Compare TOA with BOA</h3>
<p>Open the BOA and the TOA file in QGIS and visually assess the differences in the spectral signature between the SR and TOA files. Use the info tool´s graph view to investigate the spectral signatures of each of the following land cover types:</p>
<ul>
<li>Deciduous forest</li>
<li>Coniferous forest</li>
<li>Grassland</li>
<li>Cropland</li>
<li>Impervious surfaces</li>
<li>Water</li>
</ul>
<p>In your R script, take notes on the following questions:</p>
<ol style="list-style-type: lower-alpha">
<li><p>What are the most evident differences between TOA and SR reflectance spectra?</p></li>
<li><p>Briefly summarize the spectral appearance of the six land cover types, and the main difference between the TOA and SR.</p></li>
</ol>
<hr />
</div>
</div>
</div>
<div id="session-02-data-quality-cloud-masking" class="section level1">
<h1>Session 02: Data quality &amp; cloud masking</h1>
<div id="learning-goals-2" class="section level2">
<h2>Learning goals</h2>
<ul>
<li>Understand how to use the Landsat Collection 1 quality bands</li>
<li>Produce cloud / cloud shadow masks of differing confidence levels</li>
<li>Mask Landsat images</li>
</ul>
<hr />
</div>
<div id="landsat-data-quality" class="section level2">
<h2>Landsat data quality</h2>
<p>Think about the following question and exchange with your neighbor: Which issues affect the data quality of optical satellite images?</p>
<p>How to find out if a pixel is affected by any of these issues? Luckily, the USGS provides quality bands for the Landsat Collection 1 products. If we look up the <a href="https://www.usgs.gov/land-resources/nli/landsat/landsat-collection-1-level-1-quality-assessment-band">Landsat QA band website</a> to find out what this band contains, we find the following information:</p>
<p><em>“Each pixel in the QA band contains unsigned integers that represent bit-packed combinations of surface, atmospheric, and sensor conditions that can affect the overall usefulness of a given pixel.”</em></p>
<div class="figure">
<img src="fig/s02_qa_band.png" alt="False-color representation of a cloudy Landsat Level 1 image (left) and a grey-scale visualization of the Landsat QA band (right)" style="width:60.0%" />
<p class="caption">False-color representation of a cloudy Landsat Level 1 image (left) and a grey-scale visualization of the Landsat QA band (right)</p>
</div>
<p>In the following, you will learn to understand what that means. Please read this section carefully and exchange with your neighbor.</p>
<div id="the-binary-system" class="section level3">
<h3>The binary system</h3>
<p>Remember the binary numeral system (0 / FALSE or 1 / TRUE)?</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/7/75/Binary_counter.gif" alt="The binary number system. Source: Wikipedia" style="width:100.0%" />
<p class="caption">The binary number system. Source: Wikipedia</p>
</div>
<p>The binary system represents numbers through sequences of bits. Each bit has a position and a state. The positions are numbered from 0 to the total number of bits, read from right to left. The state of a bit can be either, 0, or 1. Consider the meaning of 0 as „FALSE“ or „NO“, 1 equals „TRUE“ or „YES“.</p>
<p>In the example above, five bit positions are given. Each position is sequentially numbered, starting with 0, read from right to left. By calculating 2 to the power of the bit position, we receive the value of each bit. For all bits with the value 1, we sum the respective values. Different combinations of states and positions therefore enable us to represent integer numbers.</p>
<p>The more positions or bits we have the higher numbers we can generate. With 5 bits, we can represent the numbers 0 – 31 (32 unique values), with 16 bits, we can represent the numbers 0 - 65,535 (65,536 unique values). Following the example with 5 bits, we can for instance represent these numbers:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" title="1"><span class="co"># 00001</span></a>
<a class="sourceLine" id="cb12-2" title="2"><span class="dv">0</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span><span class="op">^</span><span class="dv">4</span> <span class="op">+</span><span class="st"> </span><span class="dv">0</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span><span class="op">^</span><span class="dv">3</span> <span class="op">+</span><span class="st"> </span><span class="dv">0</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span><span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">0</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span><span class="op">^</span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span><span class="op">^</span><span class="dv">0</span></a></code></pre></div>
<pre><code>[1] 1</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" title="1"><span class="co"># 00111</span></a>
<a class="sourceLine" id="cb14-2" title="2"><span class="dv">0</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span><span class="op">^</span><span class="dv">4</span> <span class="op">+</span><span class="st"> </span><span class="dv">0</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span><span class="op">^</span><span class="dv">3</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span><span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span><span class="op">^</span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span><span class="op">^</span><span class="dv">0</span></a></code></pre></div>
<pre><code>[1] 7</code></pre>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" title="1"><span class="co"># 11111</span></a>
<a class="sourceLine" id="cb16-2" title="2"><span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span><span class="op">^</span><span class="dv">4</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span><span class="op">^</span><span class="dv">3</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span><span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span><span class="op">^</span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span><span class="op">^</span><span class="dv">0</span></a></code></pre></div>
<pre><code>[1] 31</code></pre>
</div>
<div id="landsat-qa-band" class="section level3">
<h3>Landsat QA band</h3>
<p>The Landsat QA band is coded in 16 bit, which are arranged from right to left. Each bit has a specific meaning in terms of data quality e.g. bit 4 (or position 5 from the right) means „cloud“. If bit 4 has the state 1 (or”YES“, or”TRUE"), there was a cloud detected in that pixel. If bit 4 has the state 1, the resulting integer value will be 2^4 = 16. Following this logic, different combinations of true / false conditions result in different integer values.</p>
<div class="figure">
<img src="fig/s02_landsat_qa.png" alt="Landsat QA band bit designation" style="width:80.0%" />
<p class="caption">Landsat QA band bit designation</p>
</div>
<p>In the Landsat QA band, there are furthermore single and double bits. Single bits inform about one condition in a binary manner:</p>
<p>Single bits (0, 1, and 4): - 0 = “No” = This condition does not exist - 1 = “Yes” = This condition exists</p>
<p>Double bits can represent conditions in more detail. Some double bits (5-6, 7-8, 9-10, 11-12, read from left to right) represent levels of confidence that a condition exists:</p>
<ul>
<li>00 = “Not Determined” / This condition does not exist</li>
<li>01 = “Low” = Algorithm has low to no confidence that this condition exists (0-33 percent confidence)</li>
<li>10 = “Medium” = Algorithm has medium confidence that this condition exists (34-66 percent confidence)</li>
<li>11 = “High” = Algorithm has high confidence that this condition exists (67-100 percent confidence)</li>
</ul>
<p>The radiometric saturation bits (2-3), read from left to right, represent how many bands contain radiometric saturation:</p>
<ul>
<li>00 - No bands contain saturation</li>
<li>01 - 1-2 bands contain saturation</li>
<li>10 - 3-4 bands contain saturation</li>
<li>11 - 5 or more bands contain saturation</li>
</ul>
<hr />
</div>
</div>
<div id="de-coding-quality-band-values" class="section level2">
<h2>De-coding quality band values</h2>
<p>Let´s look at the integer value 2804 to illustrate how this works. R offers a good way of dealing with bit-packed information. The <code>intToBits()</code> function converts integer numbers into sequences of bits, whereas 32 double-digit bits are returned by default.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" title="1"><span class="co"># Convert integer to bit sequence</span></a>
<a class="sourceLine" id="cb18-2" title="2"><span class="kw">intToBits</span>(<span class="dv">2804</span>)</a></code></pre></div>
<pre><code> [1] 00 00 01 00 01 01 01 01 00 01 00 01 00 00 00 00 00 00 00 00 00 00 00
[24] 00 00 00 00 00 00 00 00 00</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" title="1"><span class="co"># Convert the double-digit into single-digit bits</span></a>
<a class="sourceLine" id="cb20-2" title="2"><span class="kw">as.numeric</span>(<span class="kw">intToBits</span>(<span class="dv">2804</span>))</a></code></pre></div>
<pre><code> [1] 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" title="1"><span class="co"># We´re looking at 16 bit data, so let´s deprecate the unused bits</span></a>
<a class="sourceLine" id="cb22-2" title="2"><span class="kw">as.numeric</span>(<span class="kw">intToBits</span>(<span class="dv">2804</span>)[<span class="dv">1</span><span class="op">:</span><span class="dv">16</span>])</a></code></pre></div>
<pre><code> [1] 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0</code></pre>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" title="1"><span class="co"># Bit sequences are read from right to left, so we need to reverse the order</span></a>
<a class="sourceLine" id="cb24-2" title="2"><span class="kw">rev</span>(<span class="kw">as.numeric</span>(<span class="kw">intToBits</span>(<span class="dv">2804</span>)[<span class="dv">1</span><span class="op">:</span><span class="dv">16</span>]))</a></code></pre></div>
<pre><code> [1] 0 0 0 0 1 0 1 0 1 1 1 1 0 1 0 0</code></pre>
<p>Now we can compare with the Landsat 8 Collection 1 Level 1 QA band bit designation. What´s the pixel quality information of the integer value 2804?</p>
<div class="figure">
<img src="fig/s02_landsat_qa_decode.PNG" alt="Landsat QA band bit designation" style="width:70.0%" />
<p class="caption">Landsat QA band bit designation</p>
</div>
<p>We are looking at a cloudy pixel with radiometric saturation affecting 1-2 bands.</p>
<hr />
</div>
<div id="exercise-2" class="section level2">
<h2>Exercise</h2>
<div id="investigating-the-qa-band" class="section level3">
<h3>1) Investigating the QA band</h3>
<p>Let´s have a look at the Landsat Collection 1 Quality Band (BQA). First, load the BQA band and find the three most frequent values using <code>freq()</code>.</p>
<p>As you can see, the band contains integer values. By decoding the integer values into 16 bit binary strings, we can read the quality information for each pixel. Use the <code>intToBits()</code> function to decode the three most frequent BQA values and decipher their meaning using the Landsat quality band documentation. <code>intToBits()</code> returns 32 bits by default. Make sure you only look at bits 1 to 16. Also, keep in mind the right-to-left order when comparing the decoded bits with the table. You might want to use <code>rev()</code> to invert the order of the outputs by <code>intToBits()</code>. Note your findings as a comment in the script:</p>
<pre><code># What do the most frequent values mean? Decode each integer value into bits and 
# describe their meaning here: 

# Most frequent value: 
# Second most frequent value: 
# Third most frequent value: </code></pre>
</div>
<div id="creating-a-cloud-mask" class="section level3">
<h3>2) Creating a cloud mask</h3>
<p>By converting integer values into binary bits, we can extract specific attributes from the BQA. Let´s to this in a systematic manner by defining a function, which yields TRUE for binary codes with bit 0 = 1:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" title="1"><span class="co"># Define function to find fill values from Landsat BQA</span></a>
<a class="sourceLine" id="cb27-2" title="2">fill_pixels &lt;-<span class="st"> </span><span class="cf">function</span>(x) {<span class="kw">intToBits</span>(x)[<span class="dv">1</span>] <span class="op">==</span><span class="st"> </span>T}</a></code></pre></div>
<p>Next, use indexing and Boolean expressions to define functions which return TRUE for</p>
<ol style="list-style-type: lower-alpha">
<li>high confidence clouds or high confidence cloud shadows or fill values</li>
<li>high and medium confidence clouds or high and medium confidence cloud shadows or fill values</li>
</ol>
<p>Create a mask using the above functions. You can use <code>calc()</code>. Plot the mask and check if clouds, cloud shadows, and fill values are labeled as 1 and clear observations as 0. Write both masks to disk.</p>
<p>Open both masks in QGIS, together with an RGB representation of the image. Which mask is more accurate?</p>
</div>
<div id="masking-images" class="section level3">
<h3>3) Masking images</h3>
<p>Next, load the BOA data as a stack (VIS, nIR, swIR) and use the <code>mask()</code> function to mask clouds, cloud shadows and fill values from the image. Use the mask which you found to be more accurate. Make sure to specify the maskvalue argument accordingly. Write the masked BOA stack to disk in the <code>GTiff</code> format.</p>
</div>
</div>
<div id="reading-materials-1" class="section level2">
<h2>Reading materials</h2>
<p>In the next session, we would like to discuss the following paper:</p>
<p><a href="https://doi.org/10.1016/j.rse.2013.04.022">Griffiths, P. et al. (2014). Forest disturbances, forest recovery, and changes in forest types across the Carpathian ecoregion from 1985 to 2010 based on Landsat image composites. Remote Sensing of Environment, 151, 72–88.</a></p>
<p>In this paper, a long time series of Landsat image composites at five year intervals is used to study the dynamics of forest disturbance, recovery and changes in forest types across the Carpathian ecoregion. Please make sure to read the paper thoroughly and focus on the following broad questions:</p>
<ul>
<li>What is the motivation for this article?</li>
<li>How was it done in principle?</li>
<li>What are the key findings?</li>
<li>Are there uncertainties related to the findings?</li>
</ul>
<hr />
<!-- ################################## SESSION 03 ############################################## -->
</div>
</div>
<div id="session-03-vegetation-indices-and-data-transforms" class="section level1">
<h1>Session 03: Vegetation indices and data transforms</h1>
<div id="learning-goals-3" class="section level2">
<h2>Learning goals</h2>
<ul>
<li>Learn how to calculate NDVI, EVI and Tasseled Cap components</li>
</ul>
</div>
<div id="spectral-behavior-of-vegetation" class="section level2">
<h2>Spectral behavior of vegetation</h2>
<p>Vegetation produces a distinct spectral reflectance pattern due to its leaf and cell structure, its physiognomy, and complex stand structure. Photosynthetically inactive plant parts differ considerably from active ones across different wavelength regions. The reflectance of photosynthetically active vegetation is characterized by different factors in the VIS, nIR and SWIR:</p>
<ul>
<li><p>VIS – leaf pigments - In the visible bands the reflectance is relatively low as the majority of light is absorbed by the leaf pigments. Chlorophyll strongly absorbs energy in the blue and red wavelengths and reflects more in the green parts of the spectrum. This is why healthy vegetation appears green to the human eye.</p></li>
<li><p>nIR – cell structure - For healthy vegetation, the reflectance is much higher in the near infrared (NIR) region than in the visible region due to the cellular structure of the leaves, specifically the spongy mesophyll. Therefore healthy vegetation can be easily identified by the high NIR reflectance and generally low visible reflectance.</p></li>
<li><p>SWIR – water content - The reflectance in the shortwave infrared wavelengths is related to the water content of the vegetation and its structure. Water has strong absorption around 1.45, 1.95 and 2.50 µm . Outside these absorption bands in the SWIR region, reflectance of leaves generally increases when water content in the leaf decreases.</p></li>
</ul>
<div class="figure">
<img src="fig/s03_vegetation_spectrum.png" alt="Spectral reflectance curve of vegetation. Source: gsp.humboldt.edu" style="width:80.0%" />
<p class="caption">Spectral reflectance curve of vegetation. Source: gsp.humboldt.edu</p>
</div>
</div>
<div id="vegetation-indices" class="section level2">
<h2>Vegetation indices</h2>
<p>Vegetation indices make use of this particular reflectance signal. Most commonly known are the Normalized Difference Vegetation Index (NDVI) and the Enhanced Vegetation Index (EVI).</p>
<hr />
<div id="normalized-difference-vegetation-index-ndvi" class="section level3">
<h3>Normalized Difference Vegetation Index (NDVI)</h3>
<p>The NDVI relates the difference between the nIR and red reflectance to their sum.</p>
<p><span class="math inline">\(NDVI = (nIR – red) / (nIR + red)\)</span></p>
<p>For instance, a red reflectance of 10% and a nIR reflectance of 50% result in</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" title="1">red &lt;-<span class="st"> </span><span class="fl">0.1</span></a>
<a class="sourceLine" id="cb28-2" title="2">nIR &lt;-<span class="st"> </span><span class="fl">0.5</span></a>
<a class="sourceLine" id="cb28-3" title="3"></a>
<a class="sourceLine" id="cb28-4" title="4">ndvi &lt;-<span class="st"> </span>(nIR <span class="op">-</span><span class="st"> </span>red) <span class="op">/</span><span class="st"> </span>(nIR <span class="op">+</span><span class="st"> </span>red)</a>
<a class="sourceLine" id="cb28-5" title="5"><span class="kw">print</span>(ndvi)</a></code></pre></div>
<pre><code>[1] 0.6666667</code></pre>
<p>The NDVI is not a physical measure, but a proxy integrating different factors, such as land use / cover, incl. the amount of background signal visible in a pixel, photosynthetic activity, vitality and overall vegetation condition. It relates well to vegetation density and structure, e.g., represented by the leaf area index (LAI)</p>
<hr />
</div>
<div id="enhanced-vegetation-index-evi" class="section level3">
<h3>Enhanced Vegetation Index (EVI)</h3>
<p>The EVI often has a better correlation with biomass than NDVI, specifically in vegetation canopies with low and high LAI values.</p>
<div class="figure">
<img src="fig/s03_ndvi_evi.PNG" alt="NDVI and EVI from MODIS image composites (5-20 March 2000). Source: http://earthobservatory.nasa.gov/" style="width:100.0%" />
<p class="caption">NDVI and EVI from MODIS image composites (5-20 March 2000). Source: <a href="http://earthobservatory.nasa.gov/" class="uri">http://earthobservatory.nasa.gov/</a></p>
</div>
<p><span class="math inline">\(EVI = G * ((nIR – red) / (nIR + (C1 * red – C2 * blue) + L))\)</span></p>
<p>The EVI aims at reducing saturation effects which are common for NDVI. It includes a correction for soil background effects (L) to improve sensitivity for low density vegetation canopies. It is less sensitive to high aerosol loads, since the additional coefficients (C1 and C2) steer the aerosol resistance term, and the visible blue reflectance is used to correct for scattering that also affects the visible red.</p>
<p>Indices enhance differences in the reflectance to highlight certain features. Vegetation indices have the advantage of being simple, but the disadvantage of disregarding parts of the spectral feature space. Linear transformations, such as the Tasseled Cap Transformation, can help to overcome this limitation.</p>
<hr />
</div>
</div>
<div id="tasseled-cap-transformation" class="section level2">
<h2>Tasseled Cap Transformation</h2>
<p>The Tasseled Cap Transformation (TC) is a linear transformation of the Landsat spectral bands. It was first presented in 1976 by R.J. Kauth and G.S. Thomas of Environmental Research Institute of Michigan in an article titled “The Tasseled Cap – A Graphic Description of the Spectral-Temporal Development of Agricultural Crops as Seen by Landsat.” The TC was thus developed for analyzing agricultural lands with Landsat MSS data. The name „Tasseled Cap“ was chosen because the of the shape of phenological trajectories of crops in the nIR ~ red feature space.</p>
<div class="figure">
<img src="fig/s03_tc_concept.png" alt="Crop phenological trajectories in near infrared ~ red featurespace. Band numbers relate to Landsat MSS bands, where band 3 (6) is the near infrared and band 2 (5) is the red band." style="width:40.0%" />
<p class="caption">Crop phenological trajectories in near infrared ~ red featurespace. Band numbers relate to Landsat MSS bands, where band 3 (6) is the near infrared and band 2 (5) is the red band.</p>
</div>
<p>We can observe these trajectories by producing near infrared ~ red scatterplots for different points in time.</p>
<div class="figure">
<img src="fig/s03_sct_cln.gif" alt="Animated scatterplot of 10,000 locations of an agricultural system in southeastern Turkey in near infrared ~ red featurespace, observed within the course of one year (2015)." style="width:50.0%" />
<p class="caption">Animated scatterplot of 10,000 locations of an agricultural system in southeastern Turkey in near infrared ~ red featurespace, observed within the course of one year (2015).</p>
</div>
<p>The concept was further developed for the use with other sensors, including Landsat TM, ETM+ and OLI. It is still widely used for different applications in the context of urban, agricultural, or forest-related remote-sensing studies. Resulting from the TC, we mostly analyze three components called Brightness, Greenness, and Wetness:</p>
<ul>
<li><em>Brightness</em>: an axis along the line of soils, indicating soil brightness.</li>
<li><em>Greenness</em>: axis is perpendicular to the soil line, emphasizes near infrared and hence vegetation.</li>
<li><em>Wetness</em>: emphasizes shortwave infrared and is thereby related to water content.</li>
</ul>
<hr />
</div>
<div id="exercise-3" class="section level2">
<h2>Exercise</h2>
<p>We provide the following datasets in <a href="https://box.hu-berlin.de/f/7bb994e5cb414bf49940/?dl=1">our repository</a>:</p>
<p>…sr_data/: Four cloud-masked image chips from Landsat 8 (surface reflectance):</p>
<ul>
<li>LC081890252014031001T1-SC20170927101754 (10 March 2014)</li>
<li>LC081890252014071601T1-SC20171024094741 (16 July 2014)</li>
<li>LC081890252015082001T1-SC20170927120710 (20 August 2015)</li>
<li>LC081890252014110501T1-SC20170927102137 (05 November 2014)</li>
</ul>
<div id="compute-vegetation-indices" class="section level3">
<h3>1) Compute vegetation indices</h3>
<p>Read the March surface reflectance stack in R and calculate NDVI as well as EVI. The correction factors for calculating EVI from Landsat data are:</p>
<ul>
<li><p><span class="math inline">\(G = 2.5\)</span></p></li>
<li><p><span class="math inline">\(C1 = 6\)</span></p></li>
<li><p><span class="math inline">\(C2 = 7.5\)</span>, and</p></li>
<li><p><span class="math inline">\(L = 1\)</span>.</p></li>
</ul>
<p>Always be aware that the reflectance values in our datasets is scaled by 10,000. This will not make a difference when computing the NDVI, as we are only looking at relative differences. However, for the EVI, <span class="math inline">\(L\)</span> must be scaled by 10,000. Also, keep in mind that we commonly want to store datasets in <code>INT2S</code> data type, and therefore we need to scale our results by 10,000. Consequently, we compute the EVI from Landsat data as follows:</p>
<p><code>evi &lt;- 2.5 * ((nIR – red) / (nIR + 6 * red – 7.5 * blue + 10000))</code></p>
<p>While the computation is ongoing, proceed with preparing the code for the next task. When the computation is done, write the results to disk, using the <code>INT2S</code> data type.</p>
</div>
<div id="perform-a-tasseled-cap-transformation" class="section level3">
<h3>2) Perform a Tasseled Cap transformation</h3>
<p>Perform the TC using the March surface reflectance stack. We use the coefficients derived by <a href="https://www.sciencedirect.com/science/article/pii/0034425785901026">Crist (1985)</a>.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" title="1">tcc &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>( <span class="fl">0.2043</span>,  <span class="fl">0.4158</span>,  <span class="fl">0.5524</span>, <span class="fl">0.5741</span>,  <span class="fl">0.3124</span>,  <span class="fl">0.2303</span>, </a>
<a class="sourceLine" id="cb30-2" title="2">                <span class="fl">-0.1603</span>, <span class="fl">-0.2819</span>, <span class="fl">-0.4934</span>, <span class="fl">0.7940</span>, <span class="fl">-0.0002</span>, <span class="fl">-0.1446</span>,</a>
<a class="sourceLine" id="cb30-3" title="3">                 <span class="fl">0.0315</span>,  <span class="fl">0.2021</span>,  <span class="fl">0.3102</span>, <span class="fl">0.1594</span>, <span class="fl">-0.6806</span>, <span class="fl">-0.6109</span>), </a>
<a class="sourceLine" id="cb30-4" title="4">                <span class="dt">dimnames =</span> <span class="kw">list</span>(<span class="kw">c</span>(<span class="st">&#39;blue&#39;</span>, <span class="st">&#39;green&#39;</span>, <span class="st">&#39;red&#39;</span>, <span class="st">&#39;nIR&#39;</span>, <span class="st">&#39;swIR1&#39;</span>, <span class="st">&#39;swIR2&#39;</span>), <span class="kw">c</span>(<span class="st">&#39;brightness&#39;</span>, <span class="st">&#39;greenness&#39;</span>, <span class="st">&#39;wetness&#39;</span>)),</a>
<a class="sourceLine" id="cb30-5" title="5">                <span class="dt">ncol =</span> <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb30-6" title="6"></a>
<a class="sourceLine" id="cb30-7" title="7"><span class="kw">print</span>(tcc)</a></code></pre></div>
<pre><code>      brightness greenness wetness
blue      0.2043   -0.1603  0.0315
green     0.4158   -0.2819  0.2021
red       0.5524   -0.4934  0.3102
nIR       0.5741    0.7940  0.1594
swIR1     0.3124   -0.0002 -0.6806
swIR2     0.2303   -0.1446 -0.6109</code></pre>
<p>The TC is a linear band transformation. We can simply multiply the individual bands in the march stack with the corresponding factor and sum up the result, e.g., for TC Brightness:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" title="1">brightness &lt;-<span class="st"> </span>march.stack[[<span class="dv">1</span>]] <span class="op">*</span><span class="st"> </span>tcc[<span class="dv">1</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb32-2" title="2"><span class="st">              </span>march.stack[[<span class="dv">2</span>]] <span class="op">*</span><span class="st"> </span>tcc[<span class="dv">2</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb32-3" title="3"><span class="st">              </span>march.stack[[<span class="dv">3</span>]] <span class="op">*</span><span class="st"> </span>tcc[<span class="dv">3</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb32-4" title="4"><span class="st">              </span>march.stack[[<span class="dv">4</span>]] <span class="op">*</span><span class="st"> </span>tcc[<span class="dv">4</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb32-5" title="5"><span class="st">              </span>march.stack[[<span class="dv">5</span>]] <span class="op">*</span><span class="st"> </span>tcc[<span class="dv">5</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb32-6" title="6"><span class="st">              </span>march.stack[[<span class="dv">6</span>]] <span class="op">*</span><span class="st"> </span>tcc[<span class="dv">6</span>,<span class="dv">1</span>]</a></code></pre></div>
<p>Make sure to create an individual layer for Brightness, Greenness, and Wetness. Create a stack from the three layers. While the computation is ongoing, proceed with task 1) of the block on training data collection.</p>
<p>When the computation is completed, write the results to disk, using the <code>INT2S</code> data type. Add the NDVI, EVI, and the TC stack to the QGIS project you started in the next block. Visually explore the vegetation indices and TC components.</p>
<hr />
</div>
</div>
</div>
<div id="session-03-training-data-collection" class="section level1">
<h1>Session 03: Training data collection</h1>
<div id="learning-goals-4" class="section level2">
<h2>Learning goals</h2>
<ul>
<li>Gather training data for a broad forest type classification</li>
<li>Understand how forest types differ spectrally</li>
</ul>
<hr />
</div>
<div id="background" class="section level2">
<h2>Background</h2>
<p>Collecting training is an essential step on your way to a classified map. The training pixels will be considered representative for the classes you want to map, as classification algorithms determine class labels for unknown pixels based on their similarity to the training dataset.</p>
<div class="figure">
<img src="fig/s03_training.PNG" alt="Training points for forest type classification and resulting map output" style="width:80.0%" />
<p class="caption">Training points for forest type classification and resulting map output</p>
</div>
<p>Collecting training data is time consuming, regardless if you are collecting in the field or digitally. Small conceptual mistakes may require a revision of your training dataset. As a consequence, training data collection should be well prepared. Consider the following points.</p>
<ul>
<li><p>A precise and robust definition of your target classes based on the study region characteristics is key. Targeting a high thematic detail is beneficial, but spectral(-temporal) similarities between classes might pose limitations to a robust distinction of classes, such as tree species or crop types. In such cases, it is advised to think about a hierarchical structure to aggregate similar classes into higher level classes, such as forest types, or annual / perennial croplands.</p></li>
<li><p>Gathering as much reference information as possible. Can we find additional datasets that guide our interpretation? Is any very high resolution (VHR) imagery available? GoogleEarth is a valuable source of VHR imagery, but it is critical to account for the exact acquisition date.</p></li>
<li><p>Good knowledge of the target classes, and their spectral (temporal) characteristics in the study region is beneficial. We should consider spectrally similar classes and identify potential ways to prevent confusion, e.g., by aggregating those classes or identifying spectral features which help to separate them better.</p></li>
<li><p>A purely random point sampling is not neccessarily the best option (different from collecting independent validation data), as we might want to train small classes that are hardly captured by a random sample. Manual selection of training points is advised to circumvent this problem.</p></li>
<li><p>The image below shows the spatial distribution of six training datasets collected during an earlier iteration of the course. Some training points cluster in a subset of the study region. Ideally, however, training data should be well distributed across the study region to cover regional biophysical variability, such as different soil types, weather patterns, or topography.</p></li>
</ul>
<div class="figure">
<img src="fig/s03_train_dist.PNG" alt="Spatial distribution of six training datasets" />
<p class="caption">Spatial distribution of six training datasets</p>
</div>
<ul>
<li><p>The classification algorithm of your choice might have specific requirements towards the training data, e.g., concerning the number of samples, their distribution in the spectral feature space, or their purity (pure vs. mixed pixel). We discuss these aspects later in the course.</p></li>
<li><p>In practice, it´s important to know your training data well. Are the classes separable with the data at hand? Are essential class characteristics well represented? Are there any outliers? To learn more, it is always wise to explore the spectral characteristics of your training data points. We can do this through investigating the spectral reflectances at our training data locations (e.g., through histograms / boxplots) and comparing them between classes. That´s what we want to do today.</p></li>
</ul>
<hr />
</div>
<div id="exercise-4" class="section level2">
<h2>Exercise</h2>
<p>This exercise has two larger aims. First, you will learn to collect training data for a broad forest type classification. We provide forestry data to find representative sample pixels in QGIS. We will use the data you generate in this exercise for classification in the next session. Second, you will learn how the broad forest types appear spectrally in images acquired in different parts of the growing season.</p>
<p>We provide the following datasets in <a href="https://box.hu-berlin.de/f/7bb994e5cb414bf49940/?dl=1">our repository</a>:</p>
<p>…sr_data/: Four cloud-masked image chips from Landsat 8 (surface reflectance):</p>
<ul>
<li>LC081890252014031001T1-SC20170927101754 (10 March 2014)</li>
<li>LC081890252014071601T1-SC20171024094741 (16 July 2014)</li>
<li>LC081890252015082001T1-SC20170927120710 (20 August 2015)</li>
<li>LC081890252014110501T1-SC20170927102137 (05 November 2014)</li>
</ul>
<p>…vector/: A shapefile and a *.kmz file for GoogleEarth, which will help you to accurately delineate the Landsat pixel locations and extents for training data collection.</p>
<p>…BDL/: Forestry data collected in 2015 which is publicly available <a href="https://www.bdl.lasy.gov.pl/portal/wniosek-en">here</a>. We prepared a shapefile for the use in this session.</p>
<p>It contains the following attributes:</p>
<table>
<thead>
<tr class="header">
<th>Attribute field</th>
<th>Definition</th>
<th>Class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>species_en</td>
<td>Dominant genus in each stand</td>
<td>Ash, Beech, Fir, Spruce…</td>
</tr>
<tr class="even">
<td>part_cd</td>
<td>Share of this genus within the stand</td>
<td>0 – 100 (in %)</td>
</tr>
<tr class="odd">
<td>spec_age</td>
<td>Average age of the trees in this stand</td>
<td>Age in years</td>
</tr>
</tbody>
</table>
<div id="prepare-the-training-data-collection" class="section level3">
<h3>1) Prepare the training data collection</h3>
<p>Visualize and arrange all abovementioned datasets in QGIS. Ask us for help if you´re not familiar with QGIS. Consider the following steps:</p>
<ol style="list-style-type: lower-alpha">
<li><p>Find a good <a href="https://www.harrisgeospatial.com/Learn/Blogs/Blog-Details/ArtMID/10198/ArticleID/15691/The-Many-Band-Combinations-of-Landsat-8">false-color representation</a> of the Landsat 8 bands to highlight vegetation.</p></li>
<li><p>Visualize the forestry data by choosing distinct colors for the different tree genera (species_en).</p></li>
</ol>
<p>Which genera are dominant in the study area?</p>
<p>Generate a new point shapefile for storing the training data you will collect in the next task. It should contain the attribute fields ‘classID’ and ‘confID’ (both of type integer).</p>
<p>Watch out - make sure the shapefile has the same spatial reference system as the Landsat data.</p>
</div>
<div id="collect-training-data" class="section level3">
<h3>2) Collect training data</h3>
<p>Switch into the editing mode to locate training points and assign the corresponding class and confidence number. Please collect at least 15 pixels per class and assign them the class numbers and confidence numbers given below.</p>
<table>
<thead>
<tr class="header">
<th>Class name</th>
<th>classID</th>
<th>Confidence level</th>
<th>confID</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Deciduous forest</td>
<td>1</td>
<td>Very certain</td>
<td>1</td>
</tr>
<tr class="even">
<td>Mixed forest</td>
<td>2</td>
<td>Some uncertainties</td>
<td>2</td>
</tr>
<tr class="odd">
<td>Coniferous forest</td>
<td>3</td>
<td>Very uncertain</td>
<td>3</td>
</tr>
<tr class="even">
<td>Non-forest</td>
<td>4</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Use the multi-temporal Landsat imagery, the forestry polygons and very high resolution imagery in GoogleEarth to identify training points. The historic imagery tool in Google Earth can be extremely useful to guide your interpretation between deciduous and evergreen trees, as it contains imagery from the leaf-off phenological phase. The Landsat grid shapefile and .kmz will help you to identify and label the precise training locations for the four classes.</p>
<p>Regularly save the collected points and store the final shapefile with 60+ points in your course folder.</p>
</div>
<div id="explore-your-training-data" class="section level3">
<h3>3) Explore your training data</h3>
<p>Load your shape in R using <code>readOGR()</code>. Extract the spectral values at your point locations from the March image in R using the <code>extract()</code> function. Specify <code>sp = TRUE</code> to append the spectral values to the point shapefile.</p>
<p>Make sure the result of this task is an object of type <code>data.frame</code> named <code>sr.march</code>. Your sample points should be represented as rows and the measured variables as columns (i.e. point id, classID, confID, and 6 spectral bands).</p>
<p>Create boxplots of your surface reflectance measurements for all spectral bands, grouped according to the class number.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" title="1"><span class="co"># Load required packages</span></a>
<a class="sourceLine" id="cb33-2" title="2"><span class="kw">library</span>(ggplot2)</a>
<a class="sourceLine" id="cb33-3" title="3"><span class="kw">library</span>(reshape2)</a>
<a class="sourceLine" id="cb33-4" title="4"></a>
<a class="sourceLine" id="cb33-5" title="5"><span class="co"># Melt dataframe containing point id, classID, confID, and 6 spectral bands</span></a>
<a class="sourceLine" id="cb33-6" title="6">spectra.df &lt;-<span class="st"> </span><span class="kw">melt</span>(sr.march, <span class="dt">id.vars=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>), <span class="dt">measure.vars=</span><span class="kw">c</span>(<span class="dv">4</span><span class="op">:</span><span class="dv">9</span>))</a>
<a class="sourceLine" id="cb33-7" title="7"></a>
<a class="sourceLine" id="cb33-8" title="8"><span class="co"># Create boxplots of spectral bands per class</span></a>
<a class="sourceLine" id="cb33-9" title="9"><span class="kw">ggplot</span>(spectra.df, <span class="kw">aes</span>(<span class="dt">x=</span>variable, <span class="dt">y=</span>value, <span class="dt">color=</span>classID)) <span class="op">+</span></a>
<a class="sourceLine" id="cb33-10" title="10"><span class="st">  </span><span class="kw">geom_boxplot</span>() </a></code></pre></div>
<p>Make sure you understand what the <code>melt()</code> function is doing. Feel free to adjust the plot layout.</p>
<p>Similarly to the previous task, extract the values at your point locations from the Tasseled Cap stack. Create boxplots of the three Tasseled Cap components, grouped by the target class. Investigate the boxplots in order to investigate the differences between your target classes. Try to answer the following questions:</p>
<ul>
<li>Do the Tasseled Cap components allow for discriminating your target classes?</li>
<li>Which classes are likely difficult to separate?</li>
</ul>
<p><em>Voluntary exercise</em>: If you´re keen on exploring spectral changes over time, repeat the above procedures for the remaining images (July, August, November).</p>
<hr />
</div>
</div>
<div id="reading-materials-2" class="section level2">
<h2>Reading materials</h2>
<p>In the next session, we would like to discuss the following paper:</p>
<p><a href="https://www.researchgate.net/publication/259486369_A_Pixel-Based_Landsat_Compositing_Algorithm_for_Large_Area_Land_Cover_Mapping">Griffiths et al. (2013): Pixel-Based Landsat Compositing for Large Area Land Cover Mapping. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 6(5), 2088-2101.</a></p>
<p>This paper describes the methods used in the article you read last week. Here, a novel algorithm for large-area pixel-based compositing from Landsat data was developed. Please read the paper thoroughly, make sure you understand the underlying concept and write down any question for the discussion in our next session. Also, answer the following broad questions:</p>
<ul>
<li>What is the motivation for this article?</li>
<li>How does the algorithm work in principle?</li>
<li>Which key parameters were used for the parametric scoring?</li>
<li>What is the difference between annual and seasonal consistency?</li>
</ul>
<hr />
</div>
</div>
<div id="session-04-pixel-based-compositing" class="section level1">
<h1>Session 04: Pixel-based compositing</h1>
<hr />
<div id="learning-goals-5" class="section level2">
<h2>Learning goals</h2>
<ul>
<li>Understand the fundamentals of pixel-based image compositing</li>
<li>Parameterize a compositing function and create your own composite from multiple Landsat scenes</li>
</ul>
<hr />
</div>
<div id="background-1" class="section level2">
<h2>Background:</h2>
<p>The availability of Landsat images varies by region. Even in areas where obersvation density is high, such as North America, coverage can be reduced by clouds and quality of observations can be impacted by haze or sensor saturation. <img src="fig/s04_landsat_availability.jpg" alt="Global availability of Landsat images. Source: Wulder et al. 2016; https://doi.org/10.1016/j.rse.2015.11.032" /> Using best-pixel-compositing, we can use multiple obervations (i.e., from multiple Landsat scenes) and combine them to one consistent image composite. This allows to create cloud-free, radiometrically and phenologically consistent image composites that are contiguous over large areas. A set of rules (parameters) is used to determine the observations best suited for analysis. These parameters can include information about distance to clouds, temporal proximity to a target date and seasonal consistency.</p>
<p>One of the first global composites using Landsat data was produced using the WELD compositing approach (Roy et al. 2011, <a href="https://doi.org/10.1016/j.rse.2009.08.011" class="uri">https://doi.org/10.1016/j.rse.2009.08.011</a>). <img src="fig/s04_global_weld.jpg" alt="Monthly global WELD surface reflectance composite for June 2009. Source: https://worldview.earthdata.nasa.gov/" /></p>
<hr />
</div>
<div id="parametric-pixel-based-compositing" class="section level2">
<h2>Parametric pixel-based compositing</h2>
<ul>
<li>a method to produce a gap-free image of a (large) area</li>
<li>representing a specific point in time (target date)</li>
<li>best pixel selected according to multiple parameters (e.g. how close to target date, distance to clouds) weighted scoring allows for flexible parametrization according to user´s needs and study area characteristics</li>
</ul>
<div class="figure">
<img src="fig/s04_compositing.png" alt="Creating one pixel-based composite from three images." />
<p class="caption">Creating one pixel-based composite from three images.</p>
</div>
<hr />
</div>
<div id="best-pixel-based-compositing-in-seven-steps" class="section level2">
<h2>Best-pixel-based compositing in seven steps</h2>
<ol style="list-style-type: decimal">
<li>Determine compositing parameters, e.g. Target DOY: June 15 +/- 30 days and target year: 2015 +/- 1 year</li>
<li>Calculate DOY and year suitability (0-1) according to parameters</li>
</ol>
<div class="figure">
<img src="fig/s04_suitability_scores.png" alt="Five images to be used for best-pixel compositing and their DOY and year offsets" />
<p class="caption">Five images to be used for best-pixel compositing and their DOY and year offsets</p>
</div>
<p>We use linear functions to determine the suitability of an observation.<br />
In the plot for the DOY function below, we’re chosing a parameterization that favors observations closest to the target DOY and assign a suitability score of 0 for observations that are 50 or more days from the target date. Being 30 days from the target DOY, the May 16 2015 observation receives a suitability score of 0.4.<br />
A second function determines the suitability score for the year of observation. Again, observations close to the target year are assigned high values, while observations acquired five or more years from the target year are considered unsuitable. The resulting suitability score for the May 15 2015 observation is 1.<br />
<img src="fig/s04_suitabilityplot_doy_year.png" alt="Linear functions for the DOY and year suitability score" style="width:90.0%" /></p>
<ol start="3" style="list-style-type: decimal">
<li>Calculate pixel-level suitability (0-1), e.g. through min. distance to clouds.</li>
</ol>
<div class="figure">
<img src="fig/s04_suitability_clouds.png" alt="Distance to next cloud in pixels" />
<p class="caption">Distance to next cloud in pixels</p>
</div>
<p>To minimize the likelihood of pixels being affected by clouds, we favor observations that aren’t in close proximity to clouds. The cloud distance scoring function below assigns a suitability score of 1 as soon as the distance to the next cloud is 100 or more pixels. An observation that has a distance of 60 pixels (=1800m) to the next cloud receives a cloud distance suitability score of 0.6.</p>
<div class="figure">
<img src="fig/s04_suitabilityplot_clouds.png" alt="Linear function for the cloud suitability score" style="width:40.0%" />
<p class="caption">Linear function for the cloud suitability score</p>
</div>
<ol start="4" style="list-style-type: decimal">
<li>Define which criteria are most important for you (W = weights): <span class="math display">\[W_{DOY} = 0.5\]</span> <span class="math display">\[W_{year} = 0.2\]</span> <span class="math display">\[W_{CloudDist} = 0.3\]</span></li>
<li>Calculate a score for each pixel in each image. We can use the weighted sum of suitabilities (S = score):</li>
</ol>
<p><span class="math display">\[score = S_{DOY} * W_{DOY} + S_{Year} * W_{Year} + S_{CloudDist} * W_{CloudDist}\]</span><br />
Using the values from the exemplary plots above yields:<br />
<span class="math display">\[score = 0.4 * 0.5 + 1 * 0.2 + 0.6 * 0.3\]</span> <span class="math display">\[score = 0.58\]</span></p>
<div class="figure">
<img src="fig/s04_suitability_score_weighted.png" alt="Resulting suitability scores for each image" />
<p class="caption">Resulting suitability scores for each image</p>
</div>
<ol start="6" style="list-style-type: decimal">
<li><p>Use the best observation (= highest score) for the final composite.</p></li>
<li><p>Evaluate the results by checking for seasonal/annual consistency and cloud distance (and re-iterate) <img src="fig/s04_final_composite.jpg" /></p></li>
</ol>
<hr />
</div>
<div id="exercise-5" class="section level2">
<h2>Exercise</h2>
<p>The goal of this week’s exercise is to combine several images into best-pixel composites using a parametric compositing function. We will be working with our main script which sources the compositing function from a second script. Outsourcing functions - especially extensive ones - improves the readability of scripts and allows for using functions from different scripts. Check the help for source() if you are not familiar with sourcing R code in your script.</p>
<details>
<p><summary>Click here to see code for the parametric compositing function</summary></p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" title="1">  <span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb34-2" title="2">  <span class="co"># MSc Earth Observation Exercise 4</span></a>
<a class="sourceLine" id="cb34-3" title="3">  <span class="co"># Function for creating cloud-free composites of multiple Landsat images</span></a>
<a class="sourceLine" id="cb34-4" title="4">  <span class="co"># Requires an input data.frame (here img_list) and eight compositing </span></a>
<a class="sourceLine" id="cb34-5" title="5">  <span class="co"># parameters. Please see exercise sheet for further details.</span></a>
<a class="sourceLine" id="cb34-6" title="6">  <span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb34-7" title="7">  </a>
<a class="sourceLine" id="cb34-8" title="8">  <span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb34-9" title="9">  <span class="co"># Loading required packages here...</span></a>
<a class="sourceLine" id="cb34-10" title="10">  <span class="kw">library</span>(raster)</a>
<a class="sourceLine" id="cb34-11" title="11">  <span class="kw">library</span>(lubridate)</a>
<a class="sourceLine" id="cb34-12" title="12">  </a>
<a class="sourceLine" id="cb34-13" title="13">  <span class="co"># Change raster options to store large rasters in temp files on disk</span></a>
<a class="sourceLine" id="cb34-14" title="14">  <span class="kw">rasterOptions</span>(<span class="dt">maxmemory =</span> <span class="fl">1e6</span>)</a>
<a class="sourceLine" id="cb34-15" title="15">  </a>
<a class="sourceLine" id="cb34-16" title="16">  <span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb34-17" title="17">  <span class="co"># Function definition starts here</span></a>
<a class="sourceLine" id="cb34-18" title="18">  parametric_compositing &lt;-<span class="st"> </span><span class="cf">function</span>(img_list, target_date, </a>
<a class="sourceLine" id="cb34-19" title="19">                                   W_DOY, W_year, W_cloud_dist, </a>
<a class="sourceLine" id="cb34-20" title="20">                                   max_DOY_offset, max_year_offset, </a>
<a class="sourceLine" id="cb34-21" title="21">                                   min_cloud_dist, max_cloud_dist) {</a>
<a class="sourceLine" id="cb34-22" title="22">  <span class="co">#...</span></a>
<a class="sourceLine" id="cb34-23" title="23">  tic &lt;-<span class="st"> </span><span class="kw">Sys.time</span>()</a>
<a class="sourceLine" id="cb34-24" title="24">  <span class="kw">print</span>(<span class="kw">paste</span>(<span class="st">&#39;Start of compositing process: &#39;</span>, tic))</a>
<a class="sourceLine" id="cb34-25" title="25">  <span class="kw">print</span>(<span class="kw">paste</span>(<span class="st">&#39;Target date: &#39;</span>, target_date))</a>
<a class="sourceLine" id="cb34-26" title="26">  </a>
<a class="sourceLine" id="cb34-27" title="27">  <span class="co"># Extract target DOY and year from target_date</span></a>
<a class="sourceLine" id="cb34-28" title="28">  target_DOY &lt;-<span class="st"> </span><span class="kw">yday</span>(target_date)</a>
<a class="sourceLine" id="cb34-29" title="29">  target_year &lt;-<span class="st"> </span><span class="kw">year</span>(target_date)</a>
<a class="sourceLine" id="cb34-30" title="30">  </a>
<a class="sourceLine" id="cb34-31" title="31">  <span class="co">#...</span></a>
<a class="sourceLine" id="cb34-32" title="32">  <span class="cf">if</span>(<span class="kw">sum</span>(W_DOY, W_year, W_cloud_dist)<span class="op">!=</span><span class="dv">1</span>) { <span class="kw">stop</span>(<span class="st">&#39;Error: something wrong.&#39;</span>) }</a>
<a class="sourceLine" id="cb34-33" title="33">  </a>
<a class="sourceLine" id="cb34-34" title="34">  <span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb34-35" title="35">  <span class="co"># Calculate the scores for the DOY, year, and cloud distance criteria</span></a>
<a class="sourceLine" id="cb34-36" title="36">  <span class="kw">print</span>(<span class="st">&#39;Calculating compositing scores&#39;</span>)</a>
<a class="sourceLine" id="cb34-37" title="37">  </a>
<a class="sourceLine" id="cb34-38" title="38">  <span class="co">#...</span></a>
<a class="sourceLine" id="cb34-39" title="39">  obs_DOY &lt;-<span class="st"> </span>img_list<span class="op">$</span>DOY</a>
<a class="sourceLine" id="cb34-40" title="40">  DOY_score &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="kw">abs</span>(target_DOY <span class="op">-</span><span class="st"> </span>img_list<span class="op">$</span>DOY) <span class="op">/</span><span class="st"> </span>max_DOY_offset)</a>
<a class="sourceLine" id="cb34-41" title="41">  DOY_score[DOY_score<span class="op">&lt;</span><span class="dv">0</span>] &lt;-<span class="st"> </span><span class="ot">NA</span></a>
<a class="sourceLine" id="cb34-42" title="42">  </a>
<a class="sourceLine" id="cb34-43" title="43">  <span class="co">#...</span></a>
<a class="sourceLine" id="cb34-44" title="44">  obs_year &lt;-<span class="st"> </span>img_list<span class="op">$</span>year</a>
<a class="sourceLine" id="cb34-45" title="45">  year_score &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">-</span>(<span class="kw">abs</span>(target_year <span class="op">-</span><span class="st"> </span>obs_year) <span class="op">/</span><span class="st"> </span>max_year_offset)</a>
<a class="sourceLine" id="cb34-46" title="46">  </a>
<a class="sourceLine" id="cb34-47" title="47">  <span class="cf">if</span> (max_year_offset <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) {year_score[obs_year<span class="op">==</span>target_year] &lt;-<span class="st"> </span><span class="dv">1</span>}</a>
<a class="sourceLine" id="cb34-48" title="48">  year_score[year_score<span class="op">&lt;</span><span class="dv">0</span>] &lt;-<span class="st"> </span><span class="ot">NA</span></a>
<a class="sourceLine" id="cb34-49" title="49">  </a>
<a class="sourceLine" id="cb34-50" title="50">  <span class="co"># Get candidate images within max_DOY_offset and max_year_offset</span></a>
<a class="sourceLine" id="cb34-51" title="51">  ix &lt;-<span class="st"> </span><span class="kw">which</span>(<span class="op">!</span><span class="kw">is.na</span>(DOY_score) <span class="op">&amp;</span><span class="st"> </span><span class="op">!</span><span class="kw">is.na</span>(year_score))</a>
<a class="sourceLine" id="cb34-52" title="52">  <span class="cf">if</span> (<span class="kw">length</span>(ix)<span class="op">&gt;</span><span class="dv">1</span>) { <span class="kw">print</span>(<span class="kw">paste</span>(<span class="kw">length</span>(ix),  <span class="st">&#39;candidate images selected, calculating scores.&#39;</span>)) }</a>
<a class="sourceLine" id="cb34-53" title="53">  <span class="cf">if</span> (<span class="kw">length</span>(ix)<span class="op">&lt;</span><span class="dv">2</span>) { <span class="kw">stop</span>(<span class="st">&#39;Another error because something is wrong.&#39;</span>) }</a>
<a class="sourceLine" id="cb34-54" title="54">  </a>
<a class="sourceLine" id="cb34-55" title="55">  <span class="co"># Stack cloud distance layers of candidate images and reclassify </span></a>
<a class="sourceLine" id="cb34-56" title="56">  <span class="co"># values &lt; min_cloud_dist to NA, and values &gt; max_cloud_dist to max_cloud_dist</span></a>
<a class="sourceLine" id="cb34-57" title="57">  cloud_dist &lt;-<span class="st"> </span><span class="kw">stack</span>(<span class="kw">as.character</span>(img_list<span class="op">$</span>cloud_dist_files[ix]))</a>
<a class="sourceLine" id="cb34-58" title="58">  cloud_dist &lt;-<span class="st"> </span><span class="kw">reclassify</span>(cloud_dist, <span class="dt">rcl=</span><span class="kw">c</span>(<span class="dv">0</span>, min_cloud_dist, <span class="ot">NA</span>), <span class="dt">right=</span><span class="ot">NA</span>, <span class="dt">datatype=</span><span class="st">&#39;INT2S&#39;</span>)</a>
<a class="sourceLine" id="cb34-59" title="59">  cloud_dist &lt;-<span class="st"> </span><span class="kw">reclassify</span>(cloud_dist, <span class="dt">rcl=</span><span class="kw">c</span>(max_cloud_dist, <span class="kw">sqrt</span>(<span class="kw">nrow</span>(cloud_dist)<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="kw">ncol</span>(cloud_dist)<span class="op">^</span><span class="dv">2</span>), max_cloud_dist), <span class="dt">right=</span><span class="ot">NA</span>, <span class="dt">datatype=</span><span class="st">&#39;INT2S&#39;</span>)</a>
<a class="sourceLine" id="cb34-60" title="60">  </a>
<a class="sourceLine" id="cb34-61" title="61">  <span class="co">#...</span></a>
<a class="sourceLine" id="cb34-62" title="62">  cloud_score &lt;-<span class="st"> </span>(cloud_dist <span class="op">-</span><span class="st"> </span>min_cloud_dist) <span class="op">/</span><span class="st"> </span>(max_cloud_dist <span class="op">-</span><span class="st"> </span>min_cloud_dist)</a>
<a class="sourceLine" id="cb34-63" title="63">  </a>
<a class="sourceLine" id="cb34-64" title="64">  <span class="co">#...</span></a>
<a class="sourceLine" id="cb34-65" title="65">  obs_score &lt;-<span class="st"> </span>DOY_score[ix] <span class="op">*</span><span class="st"> </span>W_DOY <span class="op">+</span><span class="st"> </span>year_score[ix] <span class="op">*</span><span class="st"> </span>W_year <span class="op">+</span><span class="st"> </span>cloud_score <span class="op">*</span><span class="st"> </span>W_cloud_dist</a>
<a class="sourceLine" id="cb34-66" title="66">  </a>
<a class="sourceLine" id="cb34-67" title="67">  <span class="co">#...</span></a>
<a class="sourceLine" id="cb34-68" title="68">  select &lt;-<span class="st"> </span><span class="kw">which.max</span>(obs_score)</a>
<a class="sourceLine" id="cb34-69" title="69">  </a>
<a class="sourceLine" id="cb34-70" title="70">  <span class="co">#...</span></a>
<a class="sourceLine" id="cb34-71" title="71">  candidates &lt;-<span class="st"> </span><span class="kw">unique</span>(select)</a>
<a class="sourceLine" id="cb34-72" title="72">  </a>
<a class="sourceLine" id="cb34-73" title="73">  <span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb34-74" title="74">  <span class="co"># Fill composite image with pixels from the candidate images</span></a>
<a class="sourceLine" id="cb34-75" title="75">  <span class="cf">for</span> (i <span class="cf">in</span> candidates){</a>
<a class="sourceLine" id="cb34-76" title="76">    </a>
<a class="sourceLine" id="cb34-77" title="77">    <span class="co">#...</span></a>
<a class="sourceLine" id="cb34-78" title="78">    fill_image &lt;-<span class="st"> </span><span class="kw">brick</span>(<span class="kw">as.character</span>(img_list<span class="op">$</span>image_files[ix[i]]), <span class="dt">datatype=</span><span class="st">&#39;INT2S&#39;</span>)</a>
<a class="sourceLine" id="cb34-79" title="79">    </a>
<a class="sourceLine" id="cb34-80" title="80">    <span class="co">#...</span></a>
<a class="sourceLine" id="cb34-81" title="81">    <span class="cf">if</span> (i <span class="op">==</span><span class="st"> </span><span class="kw">min</span>(candidates)) { </a>
<a class="sourceLine" id="cb34-82" title="82">      composite &lt;-<span class="st"> </span><span class="kw">brick</span>(fill_image, <span class="dt">values=</span><span class="ot">FALSE</span>) </a>
<a class="sourceLine" id="cb34-83" title="83">      <span class="kw">dataType</span>(composite) &lt;-<span class="st"> &#39;INT2S&#39;</span></a>
<a class="sourceLine" id="cb34-84" title="84">      <span class="kw">values</span>(composite) &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb34-85" title="85">    }</a>
<a class="sourceLine" id="cb34-86" title="86">    </a>
<a class="sourceLine" id="cb34-87" title="87">    <span class="kw">print</span>(<span class="kw">paste0</span>(<span class="st">&#39;Filling raster with acquisition from date &#39;</span>, img_list<span class="op">$</span>date[ix[i]]))</a>
<a class="sourceLine" id="cb34-88" title="88">    fill_image.masked &lt;-<span class="st"> </span><span class="kw">mask</span>(fill_image, select, <span class="dt">maskvalue=</span>i, <span class="dt">inverse=</span>T, <span class="dt">updatevalue=</span><span class="dv">0</span>, <span class="dt">datatype=</span><span class="st">&#39;INT2S&#39;</span>)</a>
<a class="sourceLine" id="cb34-89" title="89">    fill_image.masked[<span class="kw">is.na</span>(fill_image.masked)] &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb34-90" title="90">    composite &lt;-<span class="st"> </span>composite <span class="op">+</span><span class="st"> </span>fill_image.masked</a>
<a class="sourceLine" id="cb34-91" title="91">    </a>
<a class="sourceLine" id="cb34-92" title="92">  }</a>
<a class="sourceLine" id="cb34-93" title="93">  </a>
<a class="sourceLine" id="cb34-94" title="94">  <span class="co">#...</span></a>
<a class="sourceLine" id="cb34-95" title="95">  composite_na &lt;-<span class="st"> </span><span class="kw">mask</span>(composite, select, <span class="dt">maskvalue=</span><span class="ot">NA</span>, <span class="dt">datatype=</span><span class="st">&#39;INT2S&#39;</span>)</a>
<a class="sourceLine" id="cb34-96" title="96">  </a>
<a class="sourceLine" id="cb34-97" title="97">  <span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb34-98" title="98">  <span class="co">#...</span></a>
<a class="sourceLine" id="cb34-99" title="99">  <span class="kw">print</span>(<span class="kw">paste</span>(<span class="st">&#39;NAs: &#39;</span>, <span class="kw">round</span>(<span class="kw">freq</span>(composite[[<span class="dv">1</span>]], <span class="dt">value=</span><span class="ot">NA</span>)<span class="op">/</span><span class="kw">ncell</span>(composite[[<span class="dv">1</span>]])<span class="op">*</span><span class="dv">100</span>, <span class="dt">digits=</span><span class="dv">3</span>), <span class="st">&#39; %&#39;</span>))</a>
<a class="sourceLine" id="cb34-100" title="100">  </a>
<a class="sourceLine" id="cb34-101" title="101">  <span class="co">#...</span></a>
<a class="sourceLine" id="cb34-102" title="102">  rcl_DOY &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">ncol=</span><span class="dv">2</span>, <span class="dt">data=</span><span class="kw">c</span>(candidates, obs_DOY[ix[candidates]]))</a>
<a class="sourceLine" id="cb34-103" title="103">  select_DOY &lt;-<span class="st"> </span><span class="kw">reclassify</span>(select, rcl_DOY, <span class="dt">datatype =</span> <span class="st">&#39;INT2S&#39;</span>)</a>
<a class="sourceLine" id="cb34-104" title="104">  </a>
<a class="sourceLine" id="cb34-105" title="105">  <span class="co">#...</span></a>
<a class="sourceLine" id="cb34-106" title="106">  rcl_year &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">ncol=</span><span class="dv">2</span>, <span class="dt">data=</span><span class="kw">c</span>(candidates, obs_year[ix[candidates]]))</a>
<a class="sourceLine" id="cb34-107" title="107">  select_year &lt;-<span class="st"> </span><span class="kw">reclassify</span>(select, rcl_year)</a>
<a class="sourceLine" id="cb34-108" title="108">  </a>
<a class="sourceLine" id="cb34-109" title="109">  <span class="co">#...</span></a>
<a class="sourceLine" id="cb34-110" title="110">  output &lt;-<span class="st"> </span><span class="kw">stack</span>(composite_na, select_DOY, select_year)</a>
<a class="sourceLine" id="cb34-111" title="111">  <span class="kw">print</span>(<span class="kw">paste</span>(<span class="st">&#39;End of compositing process: &#39;</span>, <span class="kw">Sys.time</span>()))</a>
<a class="sourceLine" id="cb34-112" title="112">  </a>
<a class="sourceLine" id="cb34-113" title="113">  <span class="co">#...</span></a>
<a class="sourceLine" id="cb34-114" title="114">  <span class="kw">return</span>(output)</a>
<a class="sourceLine" id="cb34-115" title="115">  </a>
<a class="sourceLine" id="cb34-116" title="116">  }</a></code></pre></div>
</details>
<details>
<p><summary>Click here to see the code for the main script calling the parametric compositing function</summary></p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" title="1">  <span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb35-2" title="2">  <span class="co"># MSc Earth Observation Exercise 4</span></a>
<a class="sourceLine" id="cb35-3" title="3">  <span class="co"># [Your Name]</span></a>
<a class="sourceLine" id="cb35-4" title="4">  <span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb35-5" title="5">  </a>
<a class="sourceLine" id="cb35-6" title="6">  <span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb35-7" title="7">  <span class="kw">library</span>(rgdal)</a>
<a class="sourceLine" id="cb35-8" title="8">  <span class="kw">library</span>(raster)</a>
<a class="sourceLine" id="cb35-9" title="9">  <span class="kw">library</span>(lubridate)</a>
<a class="sourceLine" id="cb35-10" title="10">  <span class="kw">library</span>(ggplot2)</a>
<a class="sourceLine" id="cb35-11" title="11">  <span class="kw">source</span>(<span class="st">&#39;&#39;</span>) <span class="co">#path to the parametric_compositing function</span></a>
<a class="sourceLine" id="cb35-12" title="12">  </a>
<a class="sourceLine" id="cb35-13" title="13">  <span class="co"># Change raster options to store large rasters in temp files on disk</span></a>
<a class="sourceLine" id="cb35-14" title="14">  <span class="kw">rasterOptions</span>(<span class="dt">maxmemory =</span> <span class="fl">1e6</span>)</a>
<a class="sourceLine" id="cb35-15" title="15">  </a>
<a class="sourceLine" id="cb35-16" title="16">  <span class="co">######## Define the folder that contains your data...</span></a>
<a class="sourceLine" id="cb35-17" title="17">  data.path &lt;-<span class="st"> &#39;O:/ST19_MSc-EO/S04/data/&#39;</span></a>
<a class="sourceLine" id="cb35-18" title="18">  </a>
<a class="sourceLine" id="cb35-19" title="19">  <span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb35-20" title="20">  <span class="co"># 1)</span></a>
<a class="sourceLine" id="cb35-21" title="21">  <span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb35-22" title="22">  </a>
<a class="sourceLine" id="cb35-23" title="23">  sr &lt;-<span class="st"> </span><span class="kw">list.files</span>(<span class="kw">paste0</span>(data.path, <span class="st">&#39;/sr_data&#39;</span>), <span class="dt">pattern=</span><span class="st">&quot;.tif$&quot;</span>, <span class="dt">full.names=</span>T, <span class="dt">recursive=</span>F)</a>
<a class="sourceLine" id="cb35-24" title="24">  fmask &lt;-<span class="st"> </span><span class="kw">list.files</span>(<span class="kw">paste0</span>(data.path, <span class="st">&#39;/fmask&#39;</span>), <span class="dt">pattern=</span><span class="st">&quot;.tif$&quot;</span>, <span class="dt">full.names=</span>T, <span class="dt">recursive=</span>F)</a>
<a class="sourceLine" id="cb35-25" title="25">  cd &lt;-<span class="st"> </span><span class="kw">list.files</span>(<span class="kw">paste0</span>(data.path, <span class="st">&#39;/cloud_dist&#39;</span>), <span class="dt">pattern=</span><span class="st">&quot;.tif$&quot;</span>, <span class="dt">full.names=</span>T, <span class="dt">recursive=</span>F)</a>
<a class="sourceLine" id="cb35-26" title="26">  </a>
<a class="sourceLine" id="cb35-27" title="27">  sta &lt;-<span class="st"> </span><span class="kw">nchar</span>(<span class="kw">paste0</span>(data.path,<span class="st">&#39;/sr_data/LT05228082&#39;</span>)) <span class="op">+</span><span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb35-28" title="28">  end &lt;-<span class="st"> </span>sta <span class="op">+</span><span class="st"> </span><span class="dv">6</span></a>
<a class="sourceLine" id="cb35-29" title="29">  </a>
<a class="sourceLine" id="cb35-30" title="30">  dates &lt;-<span class="st"> </span><span class="kw">as.Date</span>(<span class="kw">substr</span>(sr, sta, end), <span class="dt">format=</span><span class="st">&#39;%Y%j&#39;</span>)</a>
<a class="sourceLine" id="cb35-31" title="31">  </a>
<a class="sourceLine" id="cb35-32" title="32">  sr.sorted &lt;-<span class="st"> </span>sr[<span class="kw">order</span>(dates)]</a>
<a class="sourceLine" id="cb35-33" title="33">  cd.sorted &lt;-<span class="st"> </span>cd[<span class="kw">order</span>(dates)]</a>
<a class="sourceLine" id="cb35-34" title="34">  </a>
<a class="sourceLine" id="cb35-35" title="35">  img_list &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="st">&quot;image_files&quot;</span>=<span class="kw">as.character</span>(sr.sorted), <span class="st">&quot;cloud_dist_files&quot;</span>=<span class="kw">as.character</span>(cd.sorted) ,<span class="st">&quot;date&quot;</span>=<span class="kw">sort</span>(dates), <span class="st">&quot;DOY&quot;</span>=<span class="kw">yday</span>(<span class="kw">sort</span>(dates)), <span class="st">&quot;year&quot;</span>=<span class="kw">year</span>(<span class="kw">sort</span>(dates)))</a>
<a class="sourceLine" id="cb35-36" title="36">  </a>
<a class="sourceLine" id="cb35-37" title="37">  </a>
<a class="sourceLine" id="cb35-38" title="38">  <span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb35-39" title="39">  <span class="co"># 2)</span></a>
<a class="sourceLine" id="cb35-40" title="40">  <span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb35-41" title="41">  target_date_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">ymd</span>(<span class="st">&#39;YYYYMMDD&#39;</span>)</a>
<a class="sourceLine" id="cb35-42" title="42">  target_date_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">ymd</span>(<span class="st">&#39;YYYYMMDD&#39;</span>)</a>
<a class="sourceLine" id="cb35-43" title="43">  </a>
<a class="sourceLine" id="cb35-44" title="44">  W_DOY &lt;-<span class="st"> </span><span class="fl">0.0</span></a>
<a class="sourceLine" id="cb35-45" title="45">  W_year &lt;-<span class="st"> </span><span class="fl">0.0</span></a>
<a class="sourceLine" id="cb35-46" title="46">  W_cloud_dist &lt;-<span class="st"> </span><span class="fl">0.0</span></a>
<a class="sourceLine" id="cb35-47" title="47">  </a>
<a class="sourceLine" id="cb35-48" title="48">  max_DOY_offset &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb35-49" title="49">  max_year_offset &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb35-50" title="50">  </a>
<a class="sourceLine" id="cb35-51" title="51">  min_cloud_dist &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb35-52" title="52">  max_cloud_dist &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb35-53" title="53">  </a>
<a class="sourceLine" id="cb35-54" title="54">  composite_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">parametric_compositing</span>(img_list, target_date_<span class="dv">1</span>, </a>
<a class="sourceLine" id="cb35-55" title="55">                                       W_DOY, W_year, W_cloud_dist, </a>
<a class="sourceLine" id="cb35-56" title="56">                                       max_DOY_offset, max_year_offset, </a>
<a class="sourceLine" id="cb35-57" title="57">                                       min_cloud_dist, max_cloud_dist)</a>
<a class="sourceLine" id="cb35-58" title="58">  </a>
<a class="sourceLine" id="cb35-59" title="59">  <span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb35-60" title="60">  <span class="co"># 4)</span></a>
<a class="sourceLine" id="cb35-61" title="61">  <span class="co">#############################################################################</span></a>
<a class="sourceLine" id="cb35-62" title="62">  </a>
<a class="sourceLine" id="cb35-63" title="63">  composite_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">parametric_compositing</span>(img_list, target_date_<span class="dv">2</span>, </a>
<a class="sourceLine" id="cb35-64" title="64">                                      W_DOY, W_year, W_cloud_dist, </a>
<a class="sourceLine" id="cb35-65" title="65">                                      max_DOY_offset, max_year_offset, </a>
<a class="sourceLine" id="cb35-66" title="66">                                      min_cloud_dist, max_cloud_dist)</a></code></pre></div>
</details>
<div id="parameterization" class="section level3">
<h3>1) Parameterization</h3>
<p>The function above allows you to produce cloud-free best-pixel composites for a pre-defined target DOY. This function requires one input data.frame (see code template on how to create it) and eight input parameters:</p>
<ol style="list-style-type: lower-alpha">
<li><p><em>img_list</em>: a data frame containing five variables for each of the Landsat images:</p>
<p>$image_files: the full paths to the files in …sr_data.<br />
$cloud_dist_files: the full paths to the files in …cloud_dist.<br />
$date: the acquisition day in Date format (YYYY-MM-DD).<br />
$DOY: the acquisition day of the year.<br />
$year: the acquisition year.</p></li>
<li><p><em>target_date</em>: the target date for your composite in Date format (YYYY-MM-DD)</p></li>
<li><p><em>W_DOY</em>, <em>W_year</em>, <em>W_cloud_dist</em>: weights for the three available parameters DOY, year and distance to clouds. Must be scaled between 0 and 1 and sum up to 1, the higher the weight, the higher the importance of the criterion.</p></li>
<li><p><em>max_DOY_offset</em>, <em>max_year_offset</em>: Thresholds for the maximum allowed differences between target DOY and acquisition DOY, as well target year and acquisition year. Images exceeding these thresholds (further away in time) will be fully ignored. For instance, max_year_offset = 0 will not allow observations from a year other than the target year. By choosing these parameters, you will determine whether you prefer seasonal consistency (close to target DOY but from different years) over annual consistency (observations from same year but potentially distant DOYs). Discuss the parametrization in your group.</p></li>
<li><p><em>min_cloud_dist</em>, <em>max_cloud_dist</em>: The minimum and maximum distance to clouds. min_cloud_dist = 10 will exclude all observations which are less than 10 pixels away from a cloud. The cloud scores are linearly scaled between the minimum (score = 0) and maximum cloud distance (score = 1). Pixels with distances above max_cloud_dist will receive a score of 1.</p></li>
</ol>
</div>
<div id="defining-target-dates-and-parameters" class="section level3">
<h3>2) Defining target dates and parameters</h3>
<p>Relying on your insights from collecting training data on forest types, define two target days of the year (DOY) to capture different phenological stages. These will be used as target_date parameters later on.<br />
Make a decision concerning the compositing parameters explained in 1c, 1d and 1e.</p>
</div>
<div id="exploring-the-script-and-adding-documentation" class="section level3">
<h3>3) Exploring the script and adding documentation</h3>
<ol style="list-style-type: lower-alpha">
<li><p>Open the parametric_compositing.R script and take time to read through it in groups. Run the code line by line. Make sure you understand how the function operates. Discuss questions in your group and seek the help pages of functions you don´t know.</p></li>
<li><p>The developer did not spend sufficient time on the documentation. Make the script a bit more user-friendly by adding missing comments (#…). Make sure your comments explain what happens in each step of the function, and why. Are there bugs or sections which you would code differently?</p></li>
<li><p>Next, run the parametric_compositing() function with your parameters and write the result to disk. Include the target DOY in the filename. While the function executes, proceed with the next exercise.</p></li>
</ol>
</div>
<div id="second-run-for-target-date-2" class="section level3">
<h3>4) Second run for target date 2</h3>
<p>Repeat the compositing for the second target DOY you specified in 2) and write the results to disk.</p>
</div>
<div id="visual-inspection-and-evaluation-of-results" class="section level3">
<h3>5) Visual inspection and evaluation of results</h3>
<p>Visually inspect the quality of your compositing results in QGIS. Look at the bands containing the DOY and year flags (band 7 and 8). What worked out well, what did not? How could the quality of the composites be improved? Re-iterate with different parameters if you wish.</p>
</div>
<div id="improving-the-user-friendliness-of-the-script-optionalvoluntary-task" class="section level3">
<h3>6) Improving the user-friendliness of the script (optional/voluntary task)</h3>
<p>Make the compositing function more user friendly. Insert a couple of plot and print commands to enable the users to follow the progress of the compositing while the function is running.</p>
<p>For instance, print() how many images were used for the final composite, their acquisition dates, etc. Also, you might want to plot() the composited image after each iteration. You could add further status messages telling the user how much time single steps took.</p>
<p>Don´t forget to save the script and run the source() command in your R script to update the function after you made these changes.</p>
<hr />
</div>
</div>
<div id="reading-materials." class="section level2">
<h2>Reading materials.</h2>
<hr />
</div>
</div>
<div id="session-05-machine-learning-for-image-classification" class="section level1">
<h1>Session 05: Machine learning for image classification</h1>
<div id="learning-goals-6" class="section level2">
<h2>Learning goals</h2>
</div>
<div id="exercise-6" class="section level2">
<h2>Exercise</h2>
<p>In this exercise, we will deal with image classification using the Random Forests algorithm. Specifically, we will use your training data and your pixel-based composites from the last exercises to map forest types in the Western Beskids. We will assess the performance of multiple classification models through the out of bag error and will investigate variable importances.</p>
<div id="loading-and-preparing-training-data-training-the-classification-model" class="section level4">
<h4>1) Loading and preparing training data; training the classification model</h4>
<ol style="list-style-type: lower-alpha">
<li><p>Load the vector file containing your training data points using readOGR(). Next, create a stack()/brick() of your favourite pixel-based composite (last week´s result).</p></li>
<li><p>Use extract()to create a data.frame with training points as rows, and class labels (classID) as well as the spectral bands of your composites as columns. Remove the day of year and year flags (band 7 and 8) for the next steps. As we want to train a classification (and not a regression), the randomForest() function expects the dependent variable to be of type factor - use as.factor() for conversion of the classID column. The Random Forest algorithm cannot deal with NoData (NA) values. Remove NAs from the data.frame.</p></li>
<li><p>Train a randomForest() classification model with the data.frame created in the prior step.</p></li>
</ol>
</div>
<div id="training-additional-models-based-on-different-input-data" class="section level3">
<h3>2) Training additional models based on different input data</h3>
<p>Repeat 1) to train an additional randomForest models based on</p>
<ol style="list-style-type: lower-alpha">
<li><p>…the other composite.</p></li>
<li><p>…a stack of both composites.</p></li>
</ol>
</div>
<div id="investigating-the-models-and-classification" class="section level3">
<h3>3) Investigating the models and classification</h3>
<p>The model object resulting from 2) contains a wealth of information on the model parameters and performance. Assess the out of bag (OOB) error estimates of the trained models (1b, 2a, 2b) by inspecting the err.rate attribute of your model objects. a. Which model has the lowest OOB error? b. How does the OOB behave when increasing the number of trees in your model (ntrees)? You can access the OOB per number of trees included via err.rate. Use this information to determine a suitable value for ntrees. c. Which of the four classes has the highest OOB errors?</p>
</div>
<div id="training-a-final-model-and-investigating-variable-importances" class="section level3">
<h3>4) Training a final model and investigating variable importances</h3>
<ol style="list-style-type: lower-alpha">
<li>Train a final model with the best combination of images (3a) and ntrees (3b).</li>
<li>Investigate the variable importances using varImpPlot(). Use partialPlot() to produce partial dependence plots for your most important predictor and all four classes. Can you explain the differences between classes?</li>
</ol>
</div>
<div id="classification" class="section level3">
<h3>5) Classification</h3>
<p>Perform a classification of the image stack using the predict() function. Write the resulting map to disk in ENVI format. When doing so, consider choosing the appropriate datatype argument.</p>
</div>
</div>
<div id="reading-materials.-1" class="section level2">
<h2>Reading materials.</h2>
<hr />
</div>
</div>
<div id="session-06-accuracy-assessment-and-area-estimation" class="section level1">
<h1>Session 06: Accuracy assessment and area estimation</h1>
<div id="learning-goals-7" class="section level2">
<h2>Learning goals</h2>
</div>
<div id="reading-materials.-2" class="section level2">
<h2>Reading materials.</h2>
<hr />
</div>
</div>
<div id="session-07-multi-temporal-change-detection" class="section level1">
<h1>Session 07: Multi-temporal change detection</h1>
<div id="learning-goals-8" class="section level2">
<h2>Learning goals</h2>
</div>
<div id="reading-materials.-3" class="section level2">
<h2>Reading materials.</h2>
<hr />
</div>
</div>
<div id="session-08-spectral-temporal-metrics" class="section level1">
<h1>Session 08: Spectral-temporal metrics</h1>
<div id="learning-goals-9" class="section level2">
<h2>Learning goals</h2>
</div>
<div id="reading-materials.-4" class="section level2">
<h2>Reading materials.</h2>
<hr />
</div>
</div>
<div id="project-work" class="section level1">
<h1>Project work</h1>
<div id="phase-i" class="section level2">
<h2>Phase I</h2>
</div>
<div id="phase-ii" class="section level2">
<h2>Phase II</h2>
</div>
<div id="phase-iii" class="section level2">
<h2>Phase III</h2>
<hr />
</div>
</div>
<div id="terminology" class="section level1">
<h1>Terminology</h1>
<p>This is a non-exhaustive list of common terms and their definitions.</p>
<div id="observations" class="section level2">
<h2>Observations</h2>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Pixel">Pixel</a></li>
<li>Observation</li>
<li>Path/Row; WRS-2; Footprint; Scene: Partitions of Landsat images into approximately 185 × 185 km squares.</li>
<li>Grid: an arbitrary subdivision with square units in the target coordinate system.</li>
<li>Tile: an entity of the grid with a unique tile identifier.</li>
<li>Chip: the individual gridded images that are affiliated with the tile.</li>
<li>Scene, Image</li>
<li>Data cube, Stack</li>
<li>Time series</li>
<li>Archive</li>
<li>Collection, Tier, Processing level</li>
<li>DN, TOA, BOA</li>
</ul>
</div>
<div id="sensor-characteristics" class="section level2">
<h2>Sensor characteristics</h2>
<ul>
<li>Satellite</li>
<li>Sensor</li>
<li>Spatial resolution</li>
<li>Temporal resolution</li>
<li>Temporal coverage</li>
<li>Spectral resolution</li>
<li>Radiometric resolution</li>
<li>Bits, Bytes</li>
</ul>
</div>
<div id="data-characteristics" class="section level2">
<h2>Data characteristics</h2>
<ul>
<li>Spectral band</li>
<li>Image quality</li>
<li>Very High Resolution (VHR)</li>
<li>High Resolution</li>
<li>Medium Resolution</li>
<li>Moderate Resolution</li>
<li>Coarse Resolution</li>
<li>Time Series</li>
<li>Observation density</li>
<li>Multi-temporal</li>
<li>Hyper-temporal</li>
</ul>
</div>
<div id="higher-level-products" class="section level2">
<h2>Higher-level products</h2>
<ul>
<li>Composite / Mosaic</li>
<li>Pixel-based composites (Best observation composite)</li>
<li>Phenology-adaptive composites</li>
<li>Spectral-temporal metrics</li>
<li>Rank-band composite / metric</li>
<li>Phenometrics</li>
</ul>
</div>
<div id="time-intervals" class="section level2">
<h2>Time intervals</h2>
<ul>
<li>Multi-annual</li>
<li>Inter-annual</li>
<li>Annual</li>
<li>Intra-annual</li>
<li>Seasonal</li>
</ul>
</div>
</div>

    </div>
    <div class="col-xs-2">
        </div>
  </div>
  </div>
  </div>
  <div class="row">
    </div>
  </div>

<script>
$(document).ready(function () {
  // add bootstrap table styles to pandoc tables
  $('tr.header').parent('thead').parent('table').addClass('table table-striped table-hover');

    var images = $('.pages img');
  images.filter(function() {
      if ($(this).parent().attr("class") == "figure") {
          return(false)
      } else {
          return(true);
      }
  }).wrap("<div class='figure'></div>");
  images.addClass("image-thumb").wrap("<div class='panel-body'></div>");
  $('.figure p.caption').wrap("<div class='panel-footer'></div>");
  $('.figure').addClass('panel panel-default');
  
    $('.pages img')
 	  .addClass("image-lb");
  $('.pages').magnificPopup({
	      type:'image',
	      closeOnContentClick: false,
	      closeBtnInside: false,
        delegate: 'img',
	      gallery: {enabled: false },
          removalDelay: 500,
          callbacks: {
              beforeOpen: function() {
                // just a hack that adds mfp-anim class to markup
                this.st.image.markup = this.st.image.markup.replace('mfp-figure', 'mfp-figure mfp-with-anim');
              }
          },
          mainClass: 'mfp-move-from-top',
	      image: {
	        verticalFit: true,
            titleSrc: 'alt'
	      }
 	    });
 	
    
    $('#toc ul li').first().addClass("active");
    $('#toc ul li').attr("data-target", function() {
        return($(this).children("a").attr("href"));
    })
    $('body .section.level1').first().addClass("active");
    
    $('#toc a[href*="#"]').click(function() {

      var id = $(this).attr("href");
      if (id === "#") return;
      if (id.substring(0, 8) === "#dyntab-") return;
      toggle_page(id);

      // Menu
      var menu_entry = $(".menu li[data-target='"+id+"']");
      menu_entry.addClass("active");
      $(".menu li").not(menu_entry).removeClass("active"); 
      

    });

    function toggle_page(id) {
      $(".page").not(page).removeClass("active").hide();
      window.page = id;
      var page = $(window.page);
      window.location.hash = window.page;
      //$(this).addClass("active");

      page.show();

      var totop = setInterval(function () {
        $(".pages").animate({scrollTop: 0}, 0);
      }, 10);

      setTimeout(function () {
        page.addClass("active");
        setTimeout(function () {
          clearInterval(totop);
        }, 1000);
      }, 100);

      window.dispatchEvent(new Event('resize'));

    }


    $(".menu li").click(function () {

      toggle_page($(this).data("target"));

      // Menu
      if (!$(this).data("target")) return;
      if ($(this).is(".active")) return;
      $(".menu li").not($(this)).removeClass("active");
      $(this).addClass("active");

    });
  
    


    window.page = window.location.hash;
    if (window.page != "") {
      $(".menu").find("li[data-target=" + window.page + "]").trigger("click");
    }

    /* init material bootstrap js */
    $.material.init();
});
</script>




<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
